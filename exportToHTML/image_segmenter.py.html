<html>
<head>
<title>image_segmenter.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
image_segmenter.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2022 The MediaPipe Authors. All Rights Reserved.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>
<span class="s2">&quot;&quot;&quot;MediaPipe image segmenter task.&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">dataclasses</span>
<span class="s3">import </span><span class="s1">enum</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">Callable</span><span class="s3">, </span><span class="s1">List</span><span class="s3">, </span><span class="s1">Mapping</span><span class="s3">, </span><span class="s1">Optional</span>

<span class="s3">from </span><span class="s1">mediapipe.python </span><span class="s3">import </span><span class="s1">packet_creator</span>
<span class="s3">from </span><span class="s1">mediapipe.python </span><span class="s3">import </span><span class="s1">packet_getter</span>
<span class="s3">from </span><span class="s1">mediapipe.python._framework_bindings </span><span class="s3">import </span><span class="s1">image </span><span class="s3">as </span><span class="s1">image_module</span>
<span class="s3">from </span><span class="s1">mediapipe.python._framework_bindings </span><span class="s3">import </span><span class="s1">packet</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.cc.vision.image_segmenter.proto </span><span class="s3">import </span><span class="s1">image_segmenter_graph_options_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.cc.vision.image_segmenter.proto </span><span class="s3">import </span><span class="s1">segmenter_options_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core </span><span class="s3">import </span><span class="s1">base_options </span><span class="s3">as </span><span class="s1">base_options_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core </span><span class="s3">import </span><span class="s1">task_info </span><span class="s3">as </span><span class="s1">task_info_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core.optional_dependencies </span><span class="s3">import </span><span class="s1">doc_controls</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.vision.core </span><span class="s3">import </span><span class="s1">base_vision_task_api</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.vision.core </span><span class="s3">import </span><span class="s1">vision_task_running_mode</span>

<span class="s1">_BaseOptions = base_options_module.BaseOptions</span>
<span class="s1">_SegmenterOptionsProto = segmenter_options_pb2.SegmenterOptions</span>
<span class="s1">_ImageSegmenterGraphOptionsProto = image_segmenter_graph_options_pb2.ImageSegmenterGraphOptions</span>
<span class="s1">_RunningMode = vision_task_running_mode.VisionTaskRunningMode</span>
<span class="s1">_TaskInfo = task_info_module.TaskInfo</span>

<span class="s1">_SEGMENTATION_OUT_STREAM_NAME = </span><span class="s4">'segmented_mask_out'</span>
<span class="s1">_SEGMENTATION_TAG = </span><span class="s4">'GROUPED_SEGMENTATION'</span>
<span class="s1">_IMAGE_IN_STREAM_NAME = </span><span class="s4">'image_in'</span>
<span class="s1">_IMAGE_OUT_STREAM_NAME = </span><span class="s4">'image_out'</span>
<span class="s1">_IMAGE_TAG = </span><span class="s4">'IMAGE'</span>
<span class="s1">_TASK_GRAPH_NAME = </span><span class="s4">'mediapipe.tasks.vision.image_segmenter.ImageSegmenterGraph'</span>
<span class="s1">_MICRO_SECONDS_PER_MILLISECOND = </span><span class="s5">1000</span>


<span class="s1">@dataclasses.dataclass</span>
<span class="s3">class </span><span class="s1">ImageSegmenterOptions:</span>
  <span class="s2">&quot;&quot;&quot;Options for the image segmenter task. 
 
  Attributes: 
    base_options: Base options for the image segmenter task. 
    running_mode: The running mode of the task. Default to the image mode. Image 
      segmenter task has three running modes: 1) The image mode for segmenting 
      objects on single image inputs. 2) The video mode for segmenting objects 
      on the decoded frames of a video. 3) The live stream mode for segmenting 
      objects on a live stream of input data, such as from camera. 
    output_type: The output mask type allows specifying the type of 
      post-processing to perform on the raw model results. 
    activation: Activation function to apply to input tensor. 
    result_callback: The user-defined result callback for processing live stream 
      data. The result callback should only be specified when the running mode 
      is set to the live stream mode. 
  &quot;&quot;&quot;</span>

  <span class="s3">class </span><span class="s1">OutputType(enum.Enum):</span>
    <span class="s1">UNSPECIFIED = </span><span class="s5">0</span>
    <span class="s1">CATEGORY_MASK = </span><span class="s5">1</span>
    <span class="s1">CONFIDENCE_MASK = </span><span class="s5">2</span>

  <span class="s3">class </span><span class="s1">Activation(enum.Enum):</span>
    <span class="s1">NONE = </span><span class="s5">0</span>
    <span class="s1">SIGMOID = </span><span class="s5">1</span>
    <span class="s1">SOFTMAX = </span><span class="s5">2</span>

  <span class="s1">base_options: _BaseOptions</span>
  <span class="s1">running_mode: _RunningMode = _RunningMode.IMAGE</span>
  <span class="s1">output_type: Optional[OutputType] = OutputType.CATEGORY_MASK</span>
  <span class="s1">activation: Optional[Activation] = Activation.NONE</span>
  <span class="s1">result_callback: Optional[Callable[</span>
      <span class="s1">[List[image_module.Image]</span><span class="s3">, </span><span class="s1">image_module.Image</span><span class="s3">, </span><span class="s1">int]</span><span class="s3">, None</span><span class="s1">]] = </span><span class="s3">None</span>

  <span class="s1">@doc_controls.do_not_generate_docs</span>
  <span class="s3">def </span><span class="s1">to_pb2(self) -&gt; _ImageSegmenterGraphOptionsProto:</span>
    <span class="s2">&quot;&quot;&quot;Generates an ImageSegmenterOptions protobuf object.&quot;&quot;&quot;</span>
    <span class="s1">base_options_proto = self.base_options.to_pb2()</span>
    <span class="s1">base_options_proto.use_stream_mode = </span><span class="s3">False if </span><span class="s1">self.running_mode == _RunningMode.IMAGE </span><span class="s3">else True</span>
    <span class="s1">segmenter_options_proto = _SegmenterOptionsProto(</span>
        <span class="s1">output_type=self.output_type.value</span><span class="s3">, </span><span class="s1">activation=self.activation.value)</span>
    <span class="s3">return </span><span class="s1">_ImageSegmenterGraphOptionsProto(</span>
        <span class="s1">base_options=base_options_proto</span><span class="s3">,</span>
        <span class="s1">segmenter_options=segmenter_options_proto)</span>


<span class="s3">class </span><span class="s1">ImageSegmenter(base_vision_task_api.BaseVisionTaskApi):</span>
  <span class="s2">&quot;&quot;&quot;Class that performs image segmentation on images. 
 
  The API expects a TFLite model with mandatory TFLite Model Metadata. 
 
  Input tensor: 
    (kTfLiteUInt8/kTfLiteFloat32) 
    - image input of size `[batch x height x width x channels]`. 
    - batch inference is not supported (`batch` is required to be 1). 
    - RGB and greyscale inputs are supported (`channels` is required to be 
      1 or 3). 
    - if type is kTfLiteFloat32, NormalizationOptions are required to be 
      attached to the metadata for input normalization. 
  Output tensors: 
    (kTfLiteUInt8/kTfLiteFloat32) 
    - list of segmented masks. 
    - if `output_type` is CATEGORY_MASK, uint8 Image, Image vector of size 1. 
    - if `output_type` is CONFIDENCE_MASK, float32 Image list of size 
      `channels`. 
    - batch is always 1 
 
  An example of such model can be found at: 
  https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/metadata/2 
  &quot;&quot;&quot;</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">create_from_model_path(cls</span><span class="s3">, </span><span class="s1">model_path: str) -&gt; </span><span class="s4">'ImageSegmenter'</span><span class="s1">:</span>
    <span class="s2">&quot;&quot;&quot;Creates an `ImageSegmenter` object from a TensorFlow Lite model and the default `ImageSegmenterOptions`. 
 
    Note that the created `ImageSegmenter` instance is in image mode, for 
    performing image segmentation on single image inputs. 
 
    Args: 
      model_path: Path to the model. 
 
    Returns: 
      `ImageSegmenter` object that's created from the model file and the default 
      `ImageSegmenterOptions`. 
 
    Raises: 
      ValueError: If failed to create `ImageSegmenter` object from the provided 
        file such as invalid file path. 
      RuntimeError: If other types of error occurred. 
    &quot;&quot;&quot;</span>
    <span class="s1">base_options = _BaseOptions(model_asset_path=model_path)</span>
    <span class="s1">options = ImageSegmenterOptions(</span>
        <span class="s1">base_options=base_options</span><span class="s3">, </span><span class="s1">running_mode=_RunningMode.IMAGE)</span>
    <span class="s3">return </span><span class="s1">cls.create_from_options(options)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">create_from_options(cls</span><span class="s3">,</span>
                          <span class="s1">options: ImageSegmenterOptions) -&gt; </span><span class="s4">'ImageSegmenter'</span><span class="s1">:</span>
    <span class="s2">&quot;&quot;&quot;Creates the `ImageSegmenter` object from image segmenter options. 
 
    Args: 
      options: Options for the image segmenter task. 
 
    Returns: 
      `ImageSegmenter` object that's created from `options`. 
 
    Raises: 
      ValueError: If failed to create `ImageSegmenter` object from 
        `ImageSegmenterOptions` such as missing the model. 
      RuntimeError: If other types of error occurred. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">packets_callback(output_packets: Mapping[str</span><span class="s3">, </span><span class="s1">packet.Packet]):</span>
      <span class="s3">if </span><span class="s1">output_packets[_IMAGE_OUT_STREAM_NAME].is_empty():</span>
        <span class="s3">return</span>
      <span class="s1">segmentation_result = packet_getter.get_image_list(</span>
          <span class="s1">output_packets[_SEGMENTATION_OUT_STREAM_NAME])</span>
      <span class="s1">image = packet_getter.get_image(output_packets[_IMAGE_OUT_STREAM_NAME])</span>
      <span class="s1">timestamp = output_packets[_SEGMENTATION_OUT_STREAM_NAME].timestamp</span>
      <span class="s1">options.result_callback(segmentation_result</span><span class="s3">, </span><span class="s1">image</span><span class="s3">,</span>
                              <span class="s1">timestamp.value // _MICRO_SECONDS_PER_MILLISECOND)</span>

    <span class="s1">task_info = _TaskInfo(</span>
        <span class="s1">task_graph=_TASK_GRAPH_NAME</span><span class="s3">,</span>
        <span class="s1">input_streams=[</span><span class="s4">':'</span><span class="s1">.join([_IMAGE_TAG</span><span class="s3">, </span><span class="s1">_IMAGE_IN_STREAM_NAME])]</span><span class="s3">,</span>
        <span class="s1">output_streams=[</span>
            <span class="s4">':'</span><span class="s1">.join([_SEGMENTATION_TAG</span><span class="s3">, </span><span class="s1">_SEGMENTATION_OUT_STREAM_NAME])</span><span class="s3">,</span>
            <span class="s4">':'</span><span class="s1">.join([_IMAGE_TAG</span><span class="s3">, </span><span class="s1">_IMAGE_OUT_STREAM_NAME])</span>
        <span class="s1">]</span><span class="s3">,</span>
        <span class="s1">task_options=options)</span>
    <span class="s3">return </span><span class="s1">cls(</span>
        <span class="s1">task_info.generate_graph_config(</span>
            <span class="s1">enable_flow_limiting=options.running_mode ==</span>
            <span class="s1">_RunningMode.LIVE_STREAM)</span><span class="s3">, </span><span class="s1">options.running_mode</span><span class="s3">,</span>
        <span class="s1">packets_callback </span><span class="s3">if </span><span class="s1">options.result_callback </span><span class="s3">else None</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">segment(self</span><span class="s3">, </span><span class="s1">image: image_module.Image) -&gt; List[image_module.Image]:</span>
    <span class="s2">&quot;&quot;&quot;Performs the actual segmentation task on the provided MediaPipe Image. 
 
    Args: 
      image: MediaPipe Image. 
 
    Returns: 
      If the output_type is CATEGORY_MASK, the returned vector of images is 
      per-category segmented image mask. 
      If the output_type is CONFIDENCE_MASK, the returned vector of images 
      contains only one confidence image mask. A segmentation result object that 
      contains a list of segmentation masks as images. 
 
    Raises: 
      ValueError: If any of the input arguments is invalid. 
      RuntimeError: If image segmentation failed to run. 
    &quot;&quot;&quot;</span>
    <span class="s1">output_packets = self._process_image_data(</span>
        <span class="s1">{_IMAGE_IN_STREAM_NAME: packet_creator.create_image(image)})</span>
    <span class="s1">segmentation_result = packet_getter.get_image_list(</span>
        <span class="s1">output_packets[_SEGMENTATION_OUT_STREAM_NAME])</span>
    <span class="s3">return </span><span class="s1">segmentation_result</span>

  <span class="s3">def </span><span class="s1">segment_for_video(self</span><span class="s3">, </span><span class="s1">image: image_module.Image</span><span class="s3">,</span>
                        <span class="s1">timestamp_ms: int) -&gt; List[image_module.Image]:</span>
    <span class="s2">&quot;&quot;&quot;Performs segmentation on the provided video frames. 
 
    Only use this method when the ImageSegmenter is created with the video 
    running mode. It's required to provide the video frame's timestamp (in 
    milliseconds) along with the video frame. The input timestamps should be 
    monotonically increasing for adjacent calls of this method. 
 
    Args: 
      image: MediaPipe Image. 
      timestamp_ms: The timestamp of the input video frame in milliseconds. 
 
    Returns: 
      If the output_type is CATEGORY_MASK, the returned vector of images is 
      per-category segmented image mask. 
      If the output_type is CONFIDENCE_MASK, the returned vector of images 
      contains only one confidence image mask. A segmentation result object that 
      contains a list of segmentation masks as images. 
 
    Raises: 
      ValueError: If any of the input arguments is invalid. 
      RuntimeError: If image segmentation failed to run. 
    &quot;&quot;&quot;</span>
    <span class="s1">output_packets = self._process_video_data({</span>
        <span class="s1">_IMAGE_IN_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_image(image).at(</span>
                <span class="s1">timestamp_ms * _MICRO_SECONDS_PER_MILLISECOND)</span>
    <span class="s1">})</span>
    <span class="s1">segmentation_result = packet_getter.get_image_list(</span>
        <span class="s1">output_packets[_SEGMENTATION_OUT_STREAM_NAME])</span>
    <span class="s3">return </span><span class="s1">segmentation_result</span>

  <span class="s3">def </span><span class="s1">segment_async(self</span><span class="s3">, </span><span class="s1">image: image_module.Image</span><span class="s3">, </span><span class="s1">timestamp_ms: int) -&gt; </span><span class="s3">None</span><span class="s1">:</span>
    <span class="s2">&quot;&quot;&quot;Sends live image data (an Image with a unique timestamp) to perform image segmentation. 
 
    Only use this method when the ImageSegmenter is created with the live stream 
    running mode. The input timestamps should be monotonically increasing for 
    adjacent calls of this method. This method will return immediately after the 
    input image is accepted. The results will be available via the 
    `result_callback` provided in the `ImageSegmenterOptions`. The 
    `segment_async` method is designed to process live stream data such as 
    camera input. To lower the overall latency, image segmenter may drop the 
    input images if needed. In other words, it's not guaranteed to have output 
    per input image. 
 
    The `result_callback` prvoides: 
      - A segmentation result object that contains a list of segmentation masks 
        as images. 
      - The input image that the image segmenter runs on. 
      - The input timestamp in milliseconds. 
 
    Args: 
      image: MediaPipe Image. 
      timestamp_ms: The timestamp of the input image in milliseconds. 
 
    Raises: 
      ValueError: If the current input timestamp is smaller than what the image 
        segmenter has already processed. 
    &quot;&quot;&quot;</span>
    <span class="s1">self._send_live_stream_data({</span>
        <span class="s1">_IMAGE_IN_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_image(image).at(</span>
                <span class="s1">timestamp_ms * _MICRO_SECONDS_PER_MILLISECOND)</span>
    <span class="s1">})</span>
</pre>
</body>
</html>