<html>
<head>
<title>audio_classifier_test.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
audio_classifier_test.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2022 The MediaPipe Authors. All Rights Reserved.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>
<span class="s2">&quot;&quot;&quot;Tests for audio classifier.&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">os</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">List</span><span class="s3">, </span><span class="s1">Tuple</span>
<span class="s3">from </span><span class="s1">unittest </span><span class="s3">import </span><span class="s1">mock</span>

<span class="s3">from </span><span class="s1">absl.testing </span><span class="s3">import </span><span class="s1">absltest</span>
<span class="s3">from </span><span class="s1">absl.testing </span><span class="s3">import </span><span class="s1">parameterized</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy.io </span><span class="s3">import </span><span class="s1">wavfile</span>

<span class="s3">from </span><span class="s1">mediapipe.tasks.python.audio </span><span class="s3">import </span><span class="s1">audio_classifier</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.audio.core </span><span class="s3">import </span><span class="s1">audio_task_running_mode</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.components.containers </span><span class="s3">import </span><span class="s1">audio_data </span><span class="s3">as </span><span class="s1">audio_data_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.components.containers </span><span class="s3">import </span><span class="s1">classification_result </span><span class="s3">as </span><span class="s1">classification_result_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core </span><span class="s3">import </span><span class="s1">base_options </span><span class="s3">as </span><span class="s1">base_options_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.test </span><span class="s3">import </span><span class="s1">test_utils</span>

<span class="s1">_AudioClassifier = audio_classifier.AudioClassifier</span>
<span class="s1">_AudioClassifierOptions = audio_classifier.AudioClassifierOptions</span>
<span class="s1">_AudioClassifierResult = classification_result_module.ClassificationResult</span>
<span class="s1">_AudioData = audio_data_module.AudioData</span>
<span class="s1">_BaseOptions = base_options_module.BaseOptions</span>
<span class="s1">_RUNNING_MODE = audio_task_running_mode.AudioTaskRunningMode</span>

<span class="s1">_YAMNET_MODEL_FILE = </span><span class="s4">'yamnet_audio_classifier_with_metadata.tflite'</span>
<span class="s1">_YAMNET_MODEL_SAMPLE_RATE = </span><span class="s5">16000</span>
<span class="s1">_TWO_HEADS_MODEL_FILE = </span><span class="s4">'two_heads.tflite'</span>
<span class="s1">_SPEECH_WAV_16K_MONO = </span><span class="s4">'speech_16000_hz_mono.wav'</span>
<span class="s1">_SPEECH_WAV_48K_MONO = </span><span class="s4">'speech_48000_hz_mono.wav'</span>
<span class="s1">_TEST_DATA_DIR = </span><span class="s4">'mediapipe/tasks/testdata/audio'</span>
<span class="s1">_TWO_HEADS_WAV_16K_MONO = </span><span class="s4">'two_heads_16000_hz_mono.wav'</span>
<span class="s1">_TWO_HEADS_WAV_44K_MONO = </span><span class="s4">'two_heads_44100_hz_mono.wav'</span>
<span class="s1">_YAMNET_NUM_OF_SAMPLES = </span><span class="s5">15600</span>
<span class="s1">_MILLSECONDS_PER_SECOND = </span><span class="s5">1000</span>


<span class="s3">class </span><span class="s1">AudioClassifierTest(parameterized.TestCase):</span>

  <span class="s3">def </span><span class="s1">setUp(self):</span>
    <span class="s1">super().setUp()</span>
    <span class="s1">self.yamnet_model_path = test_utils.get_test_data_path(</span>
        <span class="s1">os.path.join(_TEST_DATA_DIR</span><span class="s3">, </span><span class="s1">_YAMNET_MODEL_FILE))</span>
    <span class="s1">self.two_heads_model_path = test_utils.get_test_data_path(</span>
        <span class="s1">os.path.join(_TEST_DATA_DIR</span><span class="s3">, </span><span class="s1">_TWO_HEADS_MODEL_FILE))</span>

  <span class="s3">def </span><span class="s1">_read_wav_file(self</span><span class="s3">, </span><span class="s1">file_name) -&gt; _AudioData:</span>
    <span class="s1">sample_rate</span><span class="s3">, </span><span class="s1">buffer = wavfile.read(</span>
        <span class="s1">test_utils.get_test_data_path(os.path.join(_TEST_DATA_DIR</span><span class="s3">, </span><span class="s1">file_name)))</span>
    <span class="s3">return </span><span class="s1">_AudioData.create_from_array(</span>
        <span class="s1">buffer.astype(float) / np.iinfo(np.int16).max</span><span class="s3">, </span><span class="s1">sample_rate)</span>

  <span class="s3">def </span><span class="s1">_read_wav_file_as_stream(self</span><span class="s3">, </span><span class="s1">file_name) -&gt; List[Tuple[_AudioData</span><span class="s3">, </span><span class="s1">int]]:</span>
    <span class="s1">sample_rate</span><span class="s3">, </span><span class="s1">buffer = wavfile.read(</span>
        <span class="s1">test_utils.get_test_data_path(os.path.join(_TEST_DATA_DIR</span><span class="s3">, </span><span class="s1">file_name)))</span>
    <span class="s1">audio_data_list = []</span>
    <span class="s1">start = </span><span class="s5">0</span>
    <span class="s1">step_size = _YAMNET_NUM_OF_SAMPLES * sample_rate / _YAMNET_MODEL_SAMPLE_RATE</span>
    <span class="s3">while </span><span class="s1">start &lt; len(buffer):</span>
      <span class="s1">end = min(start + (int)(step_size)</span><span class="s3">, </span><span class="s1">len(buffer))</span>
      <span class="s1">audio_data_list.append((_AudioData.create_from_array(</span>
          <span class="s1">buffer[start:end].astype(float) / np.iinfo(np.int16).max</span><span class="s3">,</span>
          <span class="s1">sample_rate)</span><span class="s3">, </span><span class="s1">(int)(start / sample_rate * _MILLSECONDS_PER_SECOND)))</span>
      <span class="s1">start = end</span>
    <span class="s3">return </span><span class="s1">audio_data_list</span>

  <span class="s0"># TODO: Compares the exact score values to capture unexpected</span>
  <span class="s0"># changes in the inference pipeline.</span>
  <span class="s3">def </span><span class="s1">_check_yamnet_result(</span>
      <span class="s1">self</span><span class="s3">,</span>
      <span class="s1">classification_result_list: List[_AudioClassifierResult]</span><span class="s3">,</span>
      <span class="s1">expected_num_categories=</span><span class="s5">521</span><span class="s1">):</span>
    <span class="s1">self.assertLen(classification_result_list</span><span class="s3">, </span><span class="s5">5</span><span class="s1">)</span>
    <span class="s3">for </span><span class="s1">idx</span><span class="s3">, </span><span class="s1">timestamp </span><span class="s3">in </span><span class="s1">enumerate([</span><span class="s5">0</span><span class="s3">, </span><span class="s5">975</span><span class="s3">, </span><span class="s5">1950</span><span class="s3">, </span><span class="s5">2925</span><span class="s1">]):</span>
      <span class="s1">classification_result = classification_result_list[idx]</span>
      <span class="s1">self.assertEqual(classification_result.timestamp_ms</span><span class="s3">, </span><span class="s1">timestamp)</span>
      <span class="s1">self.assertLen(classification_result.classifications</span><span class="s3">, </span><span class="s5">1</span><span class="s1">)</span>
      <span class="s1">classifcation = classification_result.classifications[</span><span class="s5">0</span><span class="s1">]</span>
      <span class="s1">self.assertEqual(classifcation.head_index</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span>
      <span class="s1">self.assertEqual(classifcation.head_name</span><span class="s3">, </span><span class="s4">'scores'</span><span class="s1">)</span>
      <span class="s1">self.assertLen(classifcation.categories</span><span class="s3">, </span><span class="s1">expected_num_categories)</span>
      <span class="s1">audio_category = classifcation.categories[</span><span class="s5">0</span><span class="s1">]</span>
      <span class="s1">self.assertEqual(audio_category.index</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span>
      <span class="s1">self.assertEqual(audio_category.category_name</span><span class="s3">, </span><span class="s4">'Speech'</span><span class="s1">)</span>
      <span class="s1">self.assertGreater(audio_category.score</span><span class="s3">, </span><span class="s5">0.9</span><span class="s1">)</span>

  <span class="s0"># TODO: Compares the exact score values to capture unexpected</span>
  <span class="s0"># changes in the inference pipeline.</span>
  <span class="s3">def </span><span class="s1">_check_two_heads_result(</span>
      <span class="s1">self</span><span class="s3">,</span>
      <span class="s1">classification_result_list: List[_AudioClassifierResult]</span><span class="s3">,</span>
      <span class="s1">first_head_expected_num_categories=</span><span class="s5">521</span><span class="s3">,</span>
      <span class="s1">second_head_expected_num_categories=</span><span class="s5">5</span><span class="s1">):</span>
    <span class="s1">self.assertGreaterEqual(len(classification_result_list)</span><span class="s3">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">self.assertLessEqual(len(classification_result_list)</span><span class="s3">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s0"># Checks the first result.</span>
    <span class="s1">classification_result = classification_result_list[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">self.assertEqual(classification_result.timestamp_ms</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">self.assertLen(classification_result.classifications</span><span class="s3">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s0"># Checks the first head.</span>
    <span class="s1">yamnet_classifcation = classification_result.classifications[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">self.assertEqual(yamnet_classifcation.head_index</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">self.assertEqual(yamnet_classifcation.head_name</span><span class="s3">, </span><span class="s4">'yamnet_classification'</span><span class="s1">)</span>
    <span class="s1">self.assertLen(yamnet_classifcation.categories</span><span class="s3">,</span>
                   <span class="s1">first_head_expected_num_categories)</span>
    <span class="s0"># Checks the second head.</span>
    <span class="s1">yamnet_category = yamnet_classifcation.categories[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">self.assertEqual(yamnet_category.index</span><span class="s3">, </span><span class="s5">508</span><span class="s1">)</span>
    <span class="s1">self.assertEqual(yamnet_category.category_name</span><span class="s3">, </span><span class="s4">'Environmental noise'</span><span class="s1">)</span>
    <span class="s1">self.assertGreater(yamnet_category.score</span><span class="s3">, </span><span class="s5">0.5</span><span class="s1">)</span>
    <span class="s1">bird_classifcation = classification_result.classifications[</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">self.assertEqual(bird_classifcation.head_index</span><span class="s3">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">self.assertEqual(bird_classifcation.head_name</span><span class="s3">, </span><span class="s4">'bird_classification'</span><span class="s1">)</span>
    <span class="s1">self.assertLen(bird_classifcation.categories</span><span class="s3">,</span>
                   <span class="s1">second_head_expected_num_categories)</span>
    <span class="s1">bird_category = bird_classifcation.categories[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">self.assertEqual(bird_category.index</span><span class="s3">, </span><span class="s5">4</span><span class="s1">)</span>
    <span class="s1">self.assertEqual(bird_category.category_name</span><span class="s3">, </span><span class="s4">'Chestnut-crowned Antpitta'</span><span class="s1">)</span>
    <span class="s1">self.assertGreater(bird_category.score</span><span class="s3">, </span><span class="s5">0.93</span><span class="s1">)</span>
    <span class="s0"># Checks the second result, if present.</span>
    <span class="s3">if </span><span class="s1">len(classification_result_list) == </span><span class="s5">2</span><span class="s1">:</span>
      <span class="s1">classification_result = classification_result_list[</span><span class="s5">1</span><span class="s1">]</span>
      <span class="s1">self.assertEqual(classification_result.timestamp_ms</span><span class="s3">, </span><span class="s5">975</span><span class="s1">)</span>
      <span class="s1">self.assertLen(classification_result.classifications</span><span class="s3">, </span><span class="s5">2</span><span class="s1">)</span>
      <span class="s0"># Checks the first head.</span>
      <span class="s1">yamnet_classifcation = classification_result.classifications[</span><span class="s5">0</span><span class="s1">]</span>
      <span class="s1">self.assertEqual(yamnet_classifcation.head_index</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span>
      <span class="s1">self.assertEqual(yamnet_classifcation.head_name</span><span class="s3">, </span><span class="s4">'yamnet_classification'</span><span class="s1">)</span>
      <span class="s1">self.assertLen(yamnet_classifcation.categories</span><span class="s3">,</span>
                     <span class="s1">first_head_expected_num_categories)</span>
      <span class="s1">yamnet_category = yamnet_classifcation.categories[</span><span class="s5">0</span><span class="s1">]</span>
      <span class="s1">self.assertEqual(yamnet_category.index</span><span class="s3">, </span><span class="s5">494</span><span class="s1">)</span>
      <span class="s1">self.assertEqual(yamnet_category.category_name</span><span class="s3">, </span><span class="s4">'Silence'</span><span class="s1">)</span>
      <span class="s1">self.assertGreater(yamnet_category.score</span><span class="s3">, </span><span class="s5">0.9</span><span class="s1">)</span>
      <span class="s1">bird_classifcation = classification_result.classifications[</span><span class="s5">1</span><span class="s1">]</span>
      <span class="s1">self.assertEqual(bird_classifcation.head_index</span><span class="s3">, </span><span class="s5">1</span><span class="s1">)</span>
      <span class="s1">self.assertEqual(bird_classifcation.head_name</span><span class="s3">, </span><span class="s4">'bird_classification'</span><span class="s1">)</span>
      <span class="s1">self.assertLen(bird_classifcation.categories</span><span class="s3">,</span>
                     <span class="s1">second_head_expected_num_categories)</span>
      <span class="s0"># Checks the second head.</span>
      <span class="s1">bird_category = bird_classifcation.categories[</span><span class="s5">0</span><span class="s1">]</span>
      <span class="s1">self.assertEqual(bird_category.index</span><span class="s3">, </span><span class="s5">1</span><span class="s1">)</span>
      <span class="s1">self.assertEqual(bird_category.category_name</span><span class="s3">, </span><span class="s4">'White-breasted Wood-Wren'</span><span class="s1">)</span>
      <span class="s1">self.assertGreater(bird_category.score</span><span class="s3">, </span><span class="s5">0.99</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">test_create_from_file_succeeds_with_valid_model_path(self):</span>
    <span class="s0"># Creates with default option and valid model file successfully.</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_model_path(</span>
        <span class="s1">self.yamnet_model_path) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s1">self.assertIsInstance(classifier</span><span class="s3">, </span><span class="s1">_AudioClassifier)</span>

  <span class="s3">def </span><span class="s1">test_create_from_options_succeeds_with_valid_model_path(self):</span>
    <span class="s0"># Creates with options containing model file successfully.</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(</span>
        <span class="s1">_AudioClassifierOptions(</span>
            <span class="s1">base_options=_BaseOptions(</span>
                <span class="s1">model_asset_path=self.yamnet_model_path))) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s1">self.assertIsInstance(classifier</span><span class="s3">, </span><span class="s1">_AudioClassifier)</span>

  <span class="s3">def </span><span class="s1">test_create_from_options_fails_with_invalid_model_path(self):</span>
    <span class="s3">with </span><span class="s1">self.assertRaisesRegex(</span>
        <span class="s1">RuntimeError</span><span class="s3">, </span><span class="s4">'Unable to open file at /path/to/invalid/model.tflite'</span><span class="s1">):</span>
      <span class="s1">base_options = _BaseOptions(</span>
          <span class="s1">model_asset_path=</span><span class="s4">'/path/to/invalid/model.tflite'</span><span class="s1">)</span>
      <span class="s1">options = _AudioClassifierOptions(base_options=base_options)</span>
      <span class="s1">_AudioClassifier.create_from_options(options)</span>

  <span class="s3">def </span><span class="s1">test_create_from_options_succeeds_with_valid_model_content(self):</span>
    <span class="s0"># Creates with options containing model content successfully.</span>
    <span class="s3">with </span><span class="s1">open(self.yamnet_model_path</span><span class="s3">, </span><span class="s4">'rb'</span><span class="s1">) </span><span class="s3">as </span><span class="s1">f:</span>
      <span class="s1">base_options = _BaseOptions(model_asset_buffer=f.read())</span>
      <span class="s1">options = _AudioClassifierOptions(base_options=base_options)</span>
      <span class="s1">classifier = _AudioClassifier.create_from_options(options)</span>
      <span class="s1">self.assertIsInstance(classifier</span><span class="s3">, </span><span class="s1">_AudioClassifier)</span>

  <span class="s1">@parameterized.parameters((_SPEECH_WAV_16K_MONO)</span><span class="s3">, </span><span class="s1">(_SPEECH_WAV_48K_MONO))</span>
  <span class="s3">def </span><span class="s1">test_classify_with_yamnet_model(self</span><span class="s3">, </span><span class="s1">audio_file):</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_model_path(</span>
        <span class="s1">self.yamnet_model_path) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s1">classification_result_list = classifier.classify(</span>
          <span class="s1">self._read_wav_file(audio_file))</span>
      <span class="s1">self._check_yamnet_result(classification_result_list)</span>

  <span class="s3">def </span><span class="s1">test_classify_with_yamnet_model_and_inputs_at_different_sample_rates(</span>
      <span class="s1">self):</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_model_path(</span>
        <span class="s1">self.yamnet_model_path) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s3">for </span><span class="s1">audio_file </span><span class="s3">in </span><span class="s1">[_SPEECH_WAV_16K_MONO</span><span class="s3">, </span><span class="s1">_SPEECH_WAV_48K_MONO]:</span>
        <span class="s1">classification_result_list = classifier.classify(</span>
            <span class="s1">self._read_wav_file(audio_file))</span>
        <span class="s1">self._check_yamnet_result(classification_result_list)</span>

  <span class="s3">def </span><span class="s1">test_max_result_options(self):</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(</span>
        <span class="s1">_AudioClassifierOptions(</span>
            <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
            <span class="s1">max_results=</span><span class="s5">1</span><span class="s1">)) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s3">for </span><span class="s1">audio_file </span><span class="s3">in </span><span class="s1">[_SPEECH_WAV_16K_MONO</span><span class="s3">, </span><span class="s1">_SPEECH_WAV_16K_MONO]:</span>
        <span class="s1">classification_result_list = classifier.classify(</span>
            <span class="s1">self._read_wav_file(audio_file))</span>
        <span class="s1">self._check_yamnet_result(</span>
            <span class="s1">classification_result_list</span><span class="s3">, </span><span class="s1">expected_num_categories=</span><span class="s5">1</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">test_score_threshold_options(self):</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(</span>
        <span class="s1">_AudioClassifierOptions(</span>
            <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
            <span class="s1">score_threshold=</span><span class="s5">0.9</span><span class="s1">)) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s3">for </span><span class="s1">audio_file </span><span class="s3">in </span><span class="s1">[_SPEECH_WAV_16K_MONO</span><span class="s3">, </span><span class="s1">_SPEECH_WAV_16K_MONO]:</span>
        <span class="s1">classification_result_list = classifier.classify(</span>
            <span class="s1">self._read_wav_file(audio_file))</span>
        <span class="s1">self._check_yamnet_result(</span>
            <span class="s1">classification_result_list</span><span class="s3">, </span><span class="s1">expected_num_categories=</span><span class="s5">1</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">test_allow_list_option(self):</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(</span>
        <span class="s1">_AudioClassifierOptions(</span>
            <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
            <span class="s1">category_allowlist=[</span><span class="s4">'Speech'</span><span class="s1">])) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s3">for </span><span class="s1">audio_file </span><span class="s3">in </span><span class="s1">[_SPEECH_WAV_16K_MONO</span><span class="s3">, </span><span class="s1">_SPEECH_WAV_16K_MONO]:</span>
        <span class="s1">classification_result_list = classifier.classify(</span>
            <span class="s1">self._read_wav_file(audio_file))</span>
        <span class="s1">self._check_yamnet_result(</span>
            <span class="s1">classification_result_list</span><span class="s3">, </span><span class="s1">expected_num_categories=</span><span class="s5">1</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">test_combined_allowlist_and_denylist(self):</span>
    <span class="s0"># Fails with combined allowlist and denylist</span>
    <span class="s3">with </span><span class="s1">self.assertRaisesRegex(</span>
        <span class="s1">ValueError</span><span class="s3">,</span>
        <span class="s4">r'`category_allowlist` and `category_denylist` are mutually '</span>
        <span class="s4">r'exclusive options.'</span><span class="s1">):</span>
      <span class="s1">options = _AudioClassifierOptions(</span>
          <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
          <span class="s1">category_allowlist=[</span><span class="s4">'foo'</span><span class="s1">]</span><span class="s3">,</span>
          <span class="s1">category_denylist=[</span><span class="s4">'bar'</span><span class="s1">])</span>
      <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(options) </span><span class="s3">as </span><span class="s1">unused_classifier:</span>
        <span class="s3">pass</span>

  <span class="s1">@parameterized.parameters((_TWO_HEADS_WAV_16K_MONO)</span><span class="s3">,</span>
                            <span class="s1">(_TWO_HEADS_WAV_44K_MONO))</span>
  <span class="s3">def </span><span class="s1">test_classify_with_two_heads_model_and_inputs_at_different_sample_rates(</span>
      <span class="s1">self</span><span class="s3">, </span><span class="s1">audio_file):</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_model_path(</span>
        <span class="s1">self.two_heads_model_path) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s1">classification_result_list = classifier.classify(</span>
          <span class="s1">self._read_wav_file(audio_file))</span>
      <span class="s1">self._check_two_heads_result(classification_result_list)</span>

  <span class="s3">def </span><span class="s1">test_classify_with_two_heads_model(self):</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_model_path(</span>
        <span class="s1">self.two_heads_model_path) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s3">for </span><span class="s1">audio_file </span><span class="s3">in </span><span class="s1">[_TWO_HEADS_WAV_16K_MONO</span><span class="s3">, </span><span class="s1">_TWO_HEADS_WAV_44K_MONO]:</span>
        <span class="s1">classification_result_list = classifier.classify(</span>
            <span class="s1">self._read_wav_file(audio_file))</span>
        <span class="s1">self._check_two_heads_result(classification_result_list)</span>

  <span class="s3">def </span><span class="s1">test_classify_with_two_heads_model_with_max_results(self):</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(</span>
        <span class="s1">_AudioClassifierOptions(</span>
            <span class="s1">base_options=_BaseOptions(</span>
                <span class="s1">model_asset_path=self.two_heads_model_path)</span><span class="s3">,</span>
            <span class="s1">max_results=</span><span class="s5">1</span><span class="s1">)) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s3">for </span><span class="s1">audio_file </span><span class="s3">in </span><span class="s1">[_TWO_HEADS_WAV_16K_MONO</span><span class="s3">, </span><span class="s1">_TWO_HEADS_WAV_44K_MONO]:</span>
        <span class="s1">classification_result_list = classifier.classify(</span>
            <span class="s1">self._read_wav_file(audio_file))</span>
        <span class="s1">self._check_two_heads_result(classification_result_list</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">test_missing_sample_rate_in_audio_clips_mode(self):</span>
    <span class="s1">options = _AudioClassifierOptions(</span>
        <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
        <span class="s1">running_mode=_RUNNING_MODE.AUDIO_CLIPS)</span>
    <span class="s3">with </span><span class="s1">self.assertRaisesRegex(ValueError</span><span class="s3">,</span>
                                <span class="s4">r'Must provide the audio sample rate'</span><span class="s1">):</span>
      <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(options) </span><span class="s3">as </span><span class="s1">classifier:</span>
        <span class="s1">classifier.classify(_AudioData(buffer_length=</span><span class="s5">100</span><span class="s1">))</span>

  <span class="s3">def </span><span class="s1">test_missing_sample_rate_in_audio_stream_mode(self):</span>
    <span class="s1">options = _AudioClassifierOptions(</span>
        <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
        <span class="s1">running_mode=_RUNNING_MODE.AUDIO_STREAM</span><span class="s3">,</span>
        <span class="s1">result_callback=mock.MagicMock())</span>
    <span class="s3">with </span><span class="s1">self.assertRaisesRegex(ValueError</span><span class="s3">,</span>
                                <span class="s4">r'provide the audio sample rate in audio data'</span><span class="s1">):</span>
      <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(options) </span><span class="s3">as </span><span class="s1">classifier:</span>
        <span class="s1">classifier.classify(_AudioData(buffer_length=</span><span class="s5">100</span><span class="s1">))</span>

  <span class="s3">def </span><span class="s1">test_missing_result_callback(self):</span>
    <span class="s1">options = _AudioClassifierOptions(</span>
        <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
        <span class="s1">running_mode=_RUNNING_MODE.AUDIO_STREAM)</span>
    <span class="s3">with </span><span class="s1">self.assertRaisesRegex(ValueError</span><span class="s3">,</span>
                                <span class="s4">r'result callback must be provided'</span><span class="s1">):</span>
      <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(options) </span><span class="s3">as </span><span class="s1">unused_classifier:</span>
        <span class="s3">pass</span>

  <span class="s3">def </span><span class="s1">test_illegal_result_callback(self):</span>
    <span class="s1">options = _AudioClassifierOptions(</span>
        <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
        <span class="s1">running_mode=_RUNNING_MODE.AUDIO_CLIPS</span><span class="s3">,</span>
        <span class="s1">result_callback=mock.MagicMock())</span>
    <span class="s3">with </span><span class="s1">self.assertRaisesRegex(ValueError</span><span class="s3">,</span>
                                <span class="s4">r'result callback should not be provided'</span><span class="s1">):</span>
      <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(options) </span><span class="s3">as </span><span class="s1">unused_classifier:</span>
        <span class="s3">pass</span>

  <span class="s3">def </span><span class="s1">test_calling_classify_in_audio_stream_mode(self):</span>
    <span class="s1">options = _AudioClassifierOptions(</span>
        <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
        <span class="s1">running_mode=_RUNNING_MODE.AUDIO_STREAM</span><span class="s3">,</span>
        <span class="s1">result_callback=mock.MagicMock())</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(options) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s3">with </span><span class="s1">self.assertRaisesRegex(ValueError</span><span class="s3">,</span>
                                  <span class="s4">r'not initialized with the audio clips mode'</span><span class="s1">):</span>
        <span class="s1">classifier.classify(self._read_wav_file(_SPEECH_WAV_16K_MONO))</span>

  <span class="s3">def </span><span class="s1">test_calling_classify_async_in_audio_clips_mode(self):</span>
    <span class="s1">options = _AudioClassifierOptions(</span>
        <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
        <span class="s1">running_mode=_RUNNING_MODE.AUDIO_CLIPS)</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(options) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s3">with </span><span class="s1">self.assertRaisesRegex(</span>
          <span class="s1">ValueError</span><span class="s3">, </span><span class="s4">r'not initialized with the audio stream mode'</span><span class="s1">):</span>
        <span class="s1">classifier.classify_async(self._read_wav_file(_SPEECH_WAV_16K_MONO)</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">test_classify_async_calls_with_illegal_timestamp(self):</span>
    <span class="s1">options = _AudioClassifierOptions(</span>
        <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
        <span class="s1">running_mode=_RUNNING_MODE.AUDIO_STREAM</span><span class="s3">,</span>
        <span class="s1">result_callback=mock.MagicMock())</span>
    <span class="s3">with </span><span class="s1">_AudioClassifier.create_from_options(options) </span><span class="s3">as </span><span class="s1">classifier:</span>
      <span class="s1">classifier.classify_async(self._read_wav_file(_SPEECH_WAV_16K_MONO)</span><span class="s3">, </span><span class="s5">100</span><span class="s1">)</span>
      <span class="s3">with </span><span class="s1">self.assertRaisesRegex(</span>
          <span class="s1">ValueError</span><span class="s3">, </span><span class="s4">r'Input timestamp must be monotonically increasing'</span><span class="s1">):</span>
        <span class="s1">classifier.classify_async(self._read_wav_file(_SPEECH_WAV_16K_MONO)</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span>

  <span class="s1">@parameterized.parameters((_SPEECH_WAV_16K_MONO)</span><span class="s3">, </span><span class="s1">(_SPEECH_WAV_48K_MONO))</span>
  <span class="s3">def </span><span class="s1">test_classify_async(self</span><span class="s3">, </span><span class="s1">audio_file):</span>
    <span class="s1">classification_result_list = []</span>

    <span class="s3">def </span><span class="s1">save_result(result: _AudioClassifierResult</span><span class="s3">, </span><span class="s1">timestamp_ms: int):</span>
      <span class="s1">result.timestamp_ms = timestamp_ms</span>
      <span class="s1">classification_result_list.append(result)</span>

    <span class="s1">options = _AudioClassifierOptions(</span>
        <span class="s1">base_options=_BaseOptions(model_asset_path=self.yamnet_model_path)</span><span class="s3">,</span>
        <span class="s1">running_mode=_RUNNING_MODE.AUDIO_STREAM</span><span class="s3">,</span>
        <span class="s1">max_results=</span><span class="s5">1</span><span class="s3">,</span>
        <span class="s1">result_callback=save_result)</span>
    <span class="s1">classifier = _AudioClassifier.create_from_options(options)</span>
    <span class="s1">audio_data_list = self._read_wav_file_as_stream(audio_file)</span>
    <span class="s3">for </span><span class="s1">audio_data</span><span class="s3">, </span><span class="s1">timestamp_ms </span><span class="s3">in </span><span class="s1">audio_data_list:</span>
      <span class="s1">classifier.classify_async(audio_data</span><span class="s3">, </span><span class="s1">timestamp_ms)</span>
    <span class="s1">classifier.close()</span>
    <span class="s1">self._check_yamnet_result(</span>
        <span class="s1">classification_result_list</span><span class="s3">, </span><span class="s1">expected_num_categories=</span><span class="s5">1</span><span class="s1">)</span>


<span class="s3">if </span><span class="s1">__name__ == </span><span class="s4">'__main__'</span><span class="s1">:</span>
  <span class="s1">absltest.main()</span>
</pre>
</body>
</html>