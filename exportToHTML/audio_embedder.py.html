<html>
<head>
<title>audio_embedder.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
audio_embedder.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2022 The MediaPipe Authors. All Rights Reserved.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>
<span class="s2">&quot;&quot;&quot;MediaPipe audio embedder task.&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">dataclasses</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">Callable</span><span class="s3">, </span><span class="s1">Mapping</span><span class="s3">, </span><span class="s1">List</span><span class="s3">, </span><span class="s1">Optional</span>

<span class="s3">from </span><span class="s1">mediapipe.python </span><span class="s3">import </span><span class="s1">packet_creator</span>
<span class="s3">from </span><span class="s1">mediapipe.python </span><span class="s3">import </span><span class="s1">packet_getter</span>
<span class="s3">from </span><span class="s1">mediapipe.python._framework_bindings </span><span class="s3">import </span><span class="s1">packet</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.cc.audio.audio_embedder.proto </span><span class="s3">import </span><span class="s1">audio_embedder_graph_options_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.cc.components.containers.proto </span><span class="s3">import </span><span class="s1">embeddings_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.cc.components.processors.proto </span><span class="s3">import </span><span class="s1">embedder_options_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.audio.core </span><span class="s3">import </span><span class="s1">audio_task_running_mode </span><span class="s3">as </span><span class="s1">running_mode_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.audio.core </span><span class="s3">import </span><span class="s1">base_audio_task_api</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.components.containers </span><span class="s3">import </span><span class="s1">audio_data </span><span class="s3">as </span><span class="s1">audio_data_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.components.containers </span><span class="s3">import </span><span class="s1">embedding_result </span><span class="s3">as </span><span class="s1">embedding_result_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.components.utils </span><span class="s3">import </span><span class="s1">cosine_similarity</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core </span><span class="s3">import </span><span class="s1">base_options </span><span class="s3">as </span><span class="s1">base_options_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core </span><span class="s3">import </span><span class="s1">task_info </span><span class="s3">as </span><span class="s1">task_info_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core.optional_dependencies </span><span class="s3">import </span><span class="s1">doc_controls</span>

<span class="s1">AudioEmbedderResult = embedding_result_module.EmbeddingResult</span>
<span class="s1">_AudioEmbedderGraphOptionsProto = audio_embedder_graph_options_pb2.AudioEmbedderGraphOptions</span>
<span class="s1">_AudioData = audio_data_module.AudioData</span>
<span class="s1">_BaseOptions = base_options_module.BaseOptions</span>
<span class="s1">_EmbedderOptionsProto = embedder_options_pb2.EmbedderOptions</span>
<span class="s1">_RunningMode = running_mode_module.AudioTaskRunningMode</span>
<span class="s1">_TaskInfo = task_info_module.TaskInfo</span>

<span class="s1">_AUDIO_IN_STREAM_NAME = </span><span class="s4">'audio_in'</span>
<span class="s1">_AUDIO_TAG = </span><span class="s4">'AUDIO'</span>
<span class="s1">_EMBEDDINGS_STREAM_NAME = </span><span class="s4">'embeddings_out'</span>
<span class="s1">_EMBEDDINGS_TAG = </span><span class="s4">'EMBEDDINGS'</span>
<span class="s1">_SAMPLE_RATE_IN_STREAM_NAME = </span><span class="s4">'sample_rate_in'</span>
<span class="s1">_SAMPLE_RATE_TAG = </span><span class="s4">'SAMPLE_RATE'</span>
<span class="s1">_TASK_GRAPH_NAME = </span><span class="s4">'mediapipe.tasks.audio.audio_embedder.AudioEmbedderGraph'</span>
<span class="s1">_TIMESTAMPTED_EMBEDDINGS_STREAM_NAME = </span><span class="s4">'timestamped_embeddings_out'</span>
<span class="s1">_TIMESTAMPTED_EMBEDDINGS_TAG = </span><span class="s4">'TIMESTAMPED_EMBEDDINGS'</span>
<span class="s1">_MICRO_SECONDS_PER_MILLISECOND = </span><span class="s5">1000</span>


<span class="s1">@dataclasses.dataclass</span>
<span class="s3">class </span><span class="s1">AudioEmbedderOptions:</span>
  <span class="s2">&quot;&quot;&quot;Options for the audio embedder task. 
 
  Attributes: 
    base_options: Base options for the audio embedder task. 
    running_mode: The running mode of the task. Default to the audio clips mode. 
      Audio embedder task has two running modes: 1) The audio clips mode for 
      running embedding extraction on independent audio clips. 2) The audio 
      stream mode for running embedding extraction on the audio stream, such as 
      from microphone. In this mode,  the &quot;result_callback&quot; below must be 
      specified to receive the embedding results asynchronously. 
    l2_normalize: Whether to normalize the returned feature vector with L2 norm. 
      Use this option only if the model does not already contain a native 
      L2_NORMALIZATION TF Lite Op. In most cases, this is already the case and 
      L2 norm is thus achieved through TF Lite inference. 
    quantize: Whether the returned embedding should be quantized to bytes via 
      scalar quantization. Embeddings are implicitly assumed to be unit-norm and 
      therefore any dimension is guaranteed to have a value in [-1.0, 1.0]. Use 
      the l2_normalize option if this is not the case. 
    result_callback: The user-defined result callback for processing audio 
      stream data. The result callback should only be specified when the running 
      mode is set to the audio stream mode. 
  &quot;&quot;&quot;</span>
  <span class="s1">base_options: _BaseOptions</span>
  <span class="s1">running_mode: _RunningMode = _RunningMode.AUDIO_CLIPS</span>
  <span class="s1">l2_normalize: Optional[bool] = </span><span class="s3">None</span>
  <span class="s1">quantize: Optional[bool] = </span><span class="s3">None</span>
  <span class="s1">result_callback: Optional[Callable[[AudioEmbedderResult</span><span class="s3">, </span><span class="s1">int]</span><span class="s3">, None</span><span class="s1">]] = </span><span class="s3">None</span>

  <span class="s1">@doc_controls.do_not_generate_docs</span>
  <span class="s3">def </span><span class="s1">to_pb2(self) -&gt; _AudioEmbedderGraphOptionsProto:</span>
    <span class="s2">&quot;&quot;&quot;Generates an AudioEmbedderOptions protobuf object.&quot;&quot;&quot;</span>
    <span class="s1">base_options_proto = self.base_options.to_pb2()</span>
    <span class="s1">base_options_proto.use_stream_mode = </span><span class="s3">False if </span><span class="s1">self.running_mode == _RunningMode.AUDIO_CLIPS </span><span class="s3">else True</span>
    <span class="s1">embedder_options_proto = _EmbedderOptionsProto(</span>
        <span class="s1">l2_normalize=self.l2_normalize</span><span class="s3">, </span><span class="s1">quantize=self.quantize)</span>

    <span class="s3">return </span><span class="s1">_AudioEmbedderGraphOptionsProto(</span>
        <span class="s1">base_options=base_options_proto</span><span class="s3">,</span>
        <span class="s1">embedder_options=embedder_options_proto)</span>


<span class="s3">class </span><span class="s1">AudioEmbedder(base_audio_task_api.BaseAudioTaskApi):</span>
  <span class="s2">&quot;&quot;&quot;Class that performs embedding extraction on audio clips or audio stream. 
 
  This API expects a TFLite model with mandatory TFLite Model Metadata that 
  contains the mandatory AudioProperties of the solo input audio tensor and the 
  optional (but recommended) label items as AssociatedFiles with type 
  TENSOR_AXIS_LABELS per output embedding tensor. 
 
  Input tensor: 
    (kTfLiteFloat32) 
    - input audio buffer of size `[batch * samples]`. 
    - batch inference is not supported (`batch` is required to be 1). 
    - for multi-channel models, the channels must be interleaved. 
  At least one output tensor with: 
    (kTfLiteUInt8/kTfLiteFloat32) 
    - `N` components corresponding to the `N` dimensions of the returned 
    feature vector for this output layer. 
    - Either 2 or 4 dimensions, i.e. `[1 x N]` or `[1 x 1 x 1 x N]`. 
  &quot;&quot;&quot;</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">create_from_model_path(cls</span><span class="s3">, </span><span class="s1">model_path: str) -&gt; </span><span class="s4">'AudioEmbedder'</span><span class="s1">:</span>
    <span class="s2">&quot;&quot;&quot;Creates an `AudioEmbedder` object from a TensorFlow Lite model and the default `AudioEmbedderOptions`. 
 
    Note that the created `AudioEmbedder` instance is in audio clips mode, for 
    embedding extraction on the independent audio clips. 
 
    Args: 
      model_path: Path to the model. 
 
    Returns: 
      `AudioEmbedder` object that's created from the model file and the 
      default `AudioEmbedderOptions`. 
 
    Raises: 
      ValueError: If failed to create `AudioEmbedder` object from the provided 
        file such as invalid file path. 
      RuntimeError: If other types of error occurred. 
    &quot;&quot;&quot;</span>
    <span class="s1">base_options = _BaseOptions(model_asset_path=model_path)</span>
    <span class="s1">options = AudioEmbedderOptions(</span>
        <span class="s1">base_options=base_options</span><span class="s3">, </span><span class="s1">running_mode=_RunningMode.AUDIO_CLIPS)</span>
    <span class="s3">return </span><span class="s1">cls.create_from_options(options)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">create_from_options(cls</span><span class="s3">,</span>
                          <span class="s1">options: AudioEmbedderOptions) -&gt; </span><span class="s4">'AudioEmbedder'</span><span class="s1">:</span>
    <span class="s2">&quot;&quot;&quot;Creates the `AudioEmbedder` object from audio embedder options. 
 
    Args: 
      options: Options for the audio embedder task. 
 
    Returns: 
      `AudioEmbedder` object that's created from `options`. 
 
    Raises: 
      ValueError: If failed to create `AudioEmbedder` object from 
        `AudioEmbedderOptions` such as missing the model. 
      RuntimeError: If other types of error occurred. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">packets_callback(output_packets: Mapping[str</span><span class="s3">, </span><span class="s1">packet.Packet]):</span>
      <span class="s1">timestamp_ms = output_packets[</span>
          <span class="s1">_EMBEDDINGS_STREAM_NAME].timestamp.value // _MICRO_SECONDS_PER_MILLISECOND</span>
      <span class="s3">if </span><span class="s1">output_packets[_EMBEDDINGS_STREAM_NAME].is_empty():</span>
        <span class="s1">options.result_callback(</span>
            <span class="s1">AudioEmbedderResult(embeddings=[])</span><span class="s3">, </span><span class="s1">timestamp_ms)</span>
        <span class="s3">return</span>
      <span class="s1">embedding_result_proto = embeddings_pb2.EmbeddingResult()</span>
      <span class="s1">embedding_result_proto.CopyFrom(</span>
          <span class="s1">packet_getter.get_proto(output_packets[_EMBEDDINGS_STREAM_NAME]))</span>
      <span class="s1">options.result_callback(</span>
          <span class="s1">AudioEmbedderResult.create_from_pb2(embedding_result_proto)</span><span class="s3">,</span>
          <span class="s1">timestamp_ms)</span>

    <span class="s1">task_info = _TaskInfo(</span>
        <span class="s1">task_graph=_TASK_GRAPH_NAME</span><span class="s3">,</span>
        <span class="s1">input_streams=[</span>
            <span class="s4">':'</span><span class="s1">.join([_AUDIO_TAG</span><span class="s3">, </span><span class="s1">_AUDIO_IN_STREAM_NAME])</span><span class="s3">,</span>
            <span class="s4">':'</span><span class="s1">.join([_SAMPLE_RATE_TAG</span><span class="s3">, </span><span class="s1">_SAMPLE_RATE_IN_STREAM_NAME])</span>
        <span class="s1">]</span><span class="s3">,</span>
        <span class="s1">output_streams=[</span>
            <span class="s4">':'</span><span class="s1">.join([_EMBEDDINGS_TAG</span><span class="s3">, </span><span class="s1">_EMBEDDINGS_STREAM_NAME])</span><span class="s3">, </span><span class="s4">':'</span><span class="s1">.join([</span>
                <span class="s1">_TIMESTAMPTED_EMBEDDINGS_TAG</span><span class="s3">,</span>
                <span class="s1">_TIMESTAMPTED_EMBEDDINGS_STREAM_NAME</span>
            <span class="s1">])</span>
        <span class="s1">]</span><span class="s3">,</span>
        <span class="s1">task_options=options)</span>
    <span class="s3">return </span><span class="s1">cls(</span>
        <span class="s0"># Audio tasks should not drop input audio due to flow limiting, which</span>
        <span class="s0"># may cause data inconsistency.</span>
        <span class="s1">task_info.generate_graph_config(enable_flow_limiting=</span><span class="s3">False</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">options.running_mode</span><span class="s3">,</span>
        <span class="s1">packets_callback </span><span class="s3">if </span><span class="s1">options.result_callback </span><span class="s3">else None</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">embed(self</span><span class="s3">, </span><span class="s1">audio_clip: _AudioData) -&gt; List[AudioEmbedderResult]:</span>
    <span class="s2">&quot;&quot;&quot;Performs embedding extraction on the provided audio clips. 
 
    The audio clip is represented as a MediaPipe AudioData. The method accepts 
    audio clips with various length and audio sample rate. It's required to 
    provide the corresponding audio sample rate within the `AudioData` object. 
 
    The input audio clip may be longer than what the model is able to process 
    in a single inference. When this occurs, the input audio clip is split into 
    multiple chunks starting at different timestamps. For this reason, this 
    function returns a vector of EmbeddingResult objects, each associated 
    ith a timestamp corresponding to the start (in milliseconds) of the chunk 
    data on which embedding extraction was carried out. 
 
    Args: 
      audio_clip: MediaPipe AudioData. 
 
    Returns: 
      An `AudioEmbedderResult` object that contains a list of embedding result 
      objects, each associated with a timestamp corresponding to the start 
      (in milliseconds) of the chunk data on which embedding extraction was 
      carried out. 
 
    Raises: 
      ValueError: If any of the input arguments is invalid, such as the sample 
        rate is not provided in the `AudioData` object. 
      RuntimeError: If audio embedding extraction failed to run. 
    &quot;&quot;&quot;</span>
    <span class="s3">if not </span><span class="s1">audio_clip.audio_format.sample_rate:</span>
      <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'Must provide the audio sample rate in audio data.'</span><span class="s1">)</span>
    <span class="s1">output_packets = self._process_audio_clip({</span>
        <span class="s1">_AUDIO_IN_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_matrix(audio_clip.buffer</span><span class="s3">, </span><span class="s1">transpose=</span><span class="s3">True</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">_SAMPLE_RATE_IN_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_double(audio_clip.audio_format.sample_rate)</span>
    <span class="s1">})</span>
    <span class="s1">output_list = []</span>
    <span class="s1">embeddings_proto_list = packet_getter.get_proto_list(</span>
        <span class="s1">output_packets[_TIMESTAMPTED_EMBEDDINGS_STREAM_NAME])</span>
    <span class="s3">for </span><span class="s1">proto </span><span class="s3">in </span><span class="s1">embeddings_proto_list:</span>
      <span class="s1">embedding_result_proto = embeddings_pb2.EmbeddingResult()</span>
      <span class="s1">embedding_result_proto.CopyFrom(proto)</span>
      <span class="s1">output_list.append(</span>
          <span class="s1">AudioEmbedderResult.create_from_pb2(embedding_result_proto))</span>
    <span class="s3">return </span><span class="s1">output_list</span>

  <span class="s3">def </span><span class="s1">embed_async(self</span><span class="s3">, </span><span class="s1">audio_block: _AudioData</span><span class="s3">, </span><span class="s1">timestamp_ms: int) -&gt; </span><span class="s3">None</span><span class="s1">:</span>
    <span class="s2">&quot;&quot;&quot;Sends audio data (a block in a continuous audio stream) to perform audio embedding extraction. 
 
    Only use this method when the AudioEmbedder is created with the audio 
    stream running mode. The input timestamps should be monotonically increasing 
    for adjacent calls of this method. This method will return immediately after 
    the input audio data is accepted. The results will be available via the 
    `result_callback` provided in the `AudioEmbedderOptions`. The 
    `embed_async` method is designed to process auido stream data such as 
    microphone input. 
 
    The input audio data may be longer than what the model is able to process 
    in a single inference. When this occurs, the input audio block is split 
    into multiple chunks. For this reason, the callback may be called multiple 
    times (once per chunk) for each call to this function. 
 
    The `result_callback` provides: 
      - An `AudioEmbedderResult` object that contains a list of 
        embeddings. 
      - The input timestamp in milliseconds. 
 
    Args: 
      audio_block: MediaPipe AudioData. 
      timestamp_ms: The timestamp of the input audio data in milliseconds. 
 
    Raises: 
      ValueError: If any of the followings: 
        1) The sample rate is not provided in the `AudioData` object or the 
        provided sample rate is inconsistent with the previously received. 
        2) The current input timestamp is smaller than what the audio 
        embedder has already processed. 
    &quot;&quot;&quot;</span>
    <span class="s3">if not </span><span class="s1">audio_block.audio_format.sample_rate:</span>
      <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'Must provide the audio sample rate in audio data.'</span><span class="s1">)</span>
    <span class="s3">if not </span><span class="s1">self._default_sample_rate:</span>
      <span class="s1">self._default_sample_rate = audio_block.audio_format.sample_rate</span>
      <span class="s1">self._set_sample_rate(_SAMPLE_RATE_IN_STREAM_NAME</span><span class="s3">,</span>
                            <span class="s1">self._default_sample_rate)</span>
    <span class="s3">elif </span><span class="s1">audio_block.audio_format.sample_rate != self._default_sample_rate:</span>
      <span class="s3">raise </span><span class="s1">ValueError(</span>
          <span class="s4">f'The audio sample rate provided in audio data: '</span>
          <span class="s4">f'</span><span class="s3">{</span><span class="s1">audio_block.audio_format.sample_rate</span><span class="s3">} </span><span class="s4">is inconsistent with '</span>
          <span class="s4">f'the previously received: </span><span class="s3">{</span><span class="s1">self._default_sample_rate</span><span class="s3">}</span><span class="s4">.'</span><span class="s1">)</span>

    <span class="s1">self._send_audio_stream_data({</span>
        <span class="s1">_AUDIO_IN_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_matrix(audio_block.buffer</span><span class="s3">, </span><span class="s1">transpose=</span><span class="s3">True</span><span class="s1">).at(</span>
                <span class="s1">timestamp_ms * _MICRO_SECONDS_PER_MILLISECOND)</span>
    <span class="s1">})</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">cosine_similarity(cls</span><span class="s3">, </span><span class="s1">u: embedding_result_module.Embedding</span><span class="s3">,</span>
                        <span class="s1">v: embedding_result_module.Embedding) -&gt; float:</span>
    <span class="s2">&quot;&quot;&quot;Utility function to compute cosine similarity between two embedding entries. 
 
    May return an InvalidArgumentError if e.g. the feature vectors are 
    of different types (quantized vs. float), have different sizes, or have a 
    an L2-norm of 0. 
 
    Args: 
      u: An embedding entry. 
      v: An embedding entry. 
 
    Returns: 
      The cosine similarity for the two embeddings. 
 
    Raises: 
      ValueError: May return an error if e.g. the feature vectors are of 
        different types (quantized vs. float), have different sizes, or have 
        an L2-norm of 0. 
    &quot;&quot;&quot;</span>
    <span class="s3">return </span><span class="s1">cosine_similarity.cosine_similarity(u</span><span class="s3">, </span><span class="s1">v)</span>
</pre>
</body>
</html>