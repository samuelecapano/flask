<html>
<head>
<title>face_detection_test.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
face_detection_test.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2021 The MediaPipe Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#      http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>
<span class="s2">&quot;&quot;&quot;Tests for mediapipe.python.solutions.face_detection.&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">os</span>
<span class="s3">import </span><span class="s1">tempfile  </span><span class="s0"># pylint: disable=unused-import</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">NamedTuple</span>

<span class="s3">from </span><span class="s1">absl.testing </span><span class="s3">import </span><span class="s1">absltest</span>
<span class="s3">from </span><span class="s1">absl.testing </span><span class="s3">import </span><span class="s1">parameterized</span>
<span class="s3">import </span><span class="s1">cv2</span>
<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">numpy.testing </span><span class="s3">as </span><span class="s1">npt</span>

<span class="s0"># resources dependency</span>
<span class="s0"># undeclared dependency</span>
<span class="s3">from </span><span class="s1">mediapipe.python.solutions </span><span class="s3">import </span><span class="s1">drawing_utils </span><span class="s3">as </span><span class="s1">mp_drawing</span>
<span class="s3">from </span><span class="s1">mediapipe.python.solutions </span><span class="s3">import </span><span class="s1">face_detection </span><span class="s3">as </span><span class="s1">mp_faces</span>

<span class="s1">TEST_IMAGE_PATH = </span><span class="s4">'mediapipe/python/solutions/testdata'</span>
<span class="s1">SHORT_RANGE_EXPECTED_FACE_KEY_POINTS = [[</span><span class="s5">363</span><span class="s3">, </span><span class="s5">182</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s5">460</span><span class="s3">, </span><span class="s5">186</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s5">420</span><span class="s3">, </span><span class="s5">241</span><span class="s1">]</span><span class="s3">,</span>
                                        <span class="s1">[</span><span class="s5">417</span><span class="s3">, </span><span class="s5">284</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s5">295</span><span class="s3">, </span><span class="s5">199</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s5">502</span><span class="s3">, </span><span class="s5">198</span><span class="s1">]]</span>
<span class="s1">FULL_RANGE_EXPECTED_FACE_KEY_POINTS = [[</span><span class="s5">363</span><span class="s3">, </span><span class="s5">181</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s5">455</span><span class="s3">, </span><span class="s5">181</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s5">413</span><span class="s3">, </span><span class="s5">233</span><span class="s1">]</span><span class="s3">,</span>
                                       <span class="s1">[</span><span class="s5">411</span><span class="s3">, </span><span class="s5">278</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s5">306</span><span class="s3">, </span><span class="s5">204</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s5">499</span><span class="s3">, </span><span class="s5">207</span><span class="s1">]]</span>
<span class="s1">DIFF_THRESHOLD = </span><span class="s5">5  </span><span class="s0"># pixels</span>


<span class="s3">class </span><span class="s1">FaceDetectionTest(parameterized.TestCase):</span>

  <span class="s3">def </span><span class="s1">_annotate(self</span><span class="s3">, </span><span class="s1">frame: np.ndarray</span><span class="s3">, </span><span class="s1">results: NamedTuple</span><span class="s3">, </span><span class="s1">idx: int):</span>
    <span class="s3">for </span><span class="s1">detection </span><span class="s3">in </span><span class="s1">results.detections:</span>
      <span class="s1">mp_drawing.draw_detection(frame</span><span class="s3">, </span><span class="s1">detection)</span>
    <span class="s1">path = os.path.join(tempfile.gettempdir()</span><span class="s3">, </span><span class="s1">self.id().split(</span><span class="s4">'.'</span><span class="s1">)[-</span><span class="s5">1</span><span class="s1">] +</span>
                                              <span class="s4">'_frame_{}.png'</span><span class="s1">.format(idx))</span>
    <span class="s1">cv2.imwrite(path</span><span class="s3">, </span><span class="s1">frame)</span>

  <span class="s3">def </span><span class="s1">test_invalid_image_shape(self):</span>
    <span class="s3">with </span><span class="s1">mp_faces.FaceDetection() </span><span class="s3">as </span><span class="s1">faces:</span>
      <span class="s3">with </span><span class="s1">self.assertRaisesRegex(</span>
          <span class="s1">ValueError</span><span class="s3">, </span><span class="s4">'Input image must contain three channel rgb data.'</span><span class="s1">):</span>
        <span class="s1">faces.process(np.arange(</span><span class="s5">36</span><span class="s3">, </span><span class="s1">dtype=np.uint8).reshape(</span><span class="s5">3</span><span class="s3">, </span><span class="s5">3</span><span class="s3">, </span><span class="s5">4</span><span class="s1">))</span>

  <span class="s3">def </span><span class="s1">test_blank_image(self):</span>
    <span class="s1">image = np.zeros([</span><span class="s5">100</span><span class="s3">, </span><span class="s5">100</span><span class="s3">, </span><span class="s5">3</span><span class="s1">]</span><span class="s3">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">image.fill(</span><span class="s5">255</span><span class="s1">)</span>
    <span class="s3">with </span><span class="s1">mp_faces.FaceDetection(min_detection_confidence=</span><span class="s5">0.5</span><span class="s1">) </span><span class="s3">as </span><span class="s1">faces:</span>
      <span class="s1">results = faces.process(image)</span>
      <span class="s1">self.assertIsNone(results.detections)</span>

  <span class="s1">@parameterized.named_parameters((</span><span class="s4">'short_range_model'</span><span class="s3">, </span><span class="s5">0</span><span class="s1">)</span><span class="s3">,</span>
                                  <span class="s1">(</span><span class="s4">'full_range_model'</span><span class="s3">, </span><span class="s5">1</span><span class="s1">))</span>
  <span class="s3">def </span><span class="s1">test_face(self</span><span class="s3">, </span><span class="s1">model_selection):</span>
    <span class="s1">image_path = os.path.join(os.path.dirname(__file__)</span><span class="s3">,</span>
                              <span class="s4">'testdata/portrait.jpg'</span><span class="s1">)</span>
    <span class="s1">image = cv2.imread(image_path)</span>
    <span class="s1">rows</span><span class="s3">, </span><span class="s1">cols</span><span class="s3">, </span><span class="s1">_ = image.shape</span>
    <span class="s3">with </span><span class="s1">mp_faces.FaceDetection(</span>
        <span class="s1">min_detection_confidence=</span><span class="s5">0.5</span><span class="s3">, </span><span class="s1">model_selection=model_selection) </span><span class="s3">as </span><span class="s1">faces:</span>
      <span class="s3">for </span><span class="s1">idx </span><span class="s3">in </span><span class="s1">range(</span><span class="s5">5</span><span class="s1">):</span>
        <span class="s1">results = faces.process(cv2.cvtColor(image</span><span class="s3">, </span><span class="s1">cv2.COLOR_BGR2RGB))</span>
        <span class="s1">self._annotate(image.copy()</span><span class="s3">, </span><span class="s1">results</span><span class="s3">, </span><span class="s1">idx)</span>
        <span class="s1">location_data = results.detections[</span><span class="s5">0</span><span class="s1">].location_data</span>
        <span class="s1">x = [keypoint.x * cols </span><span class="s3">for </span><span class="s1">keypoint </span><span class="s3">in </span><span class="s1">location_data.relative_keypoints]</span>
        <span class="s1">y = [keypoint.y * rows </span><span class="s3">for </span><span class="s1">keypoint </span><span class="s3">in </span><span class="s1">location_data.relative_keypoints]</span>
        <span class="s1">face_keypoints = np.column_stack((x</span><span class="s3">, </span><span class="s1">y))</span>
        <span class="s3">if </span><span class="s1">model_selection == </span><span class="s5">0</span><span class="s1">:</span>
          <span class="s1">prediction_error = np.abs(</span>
              <span class="s1">np.asarray(face_keypoints) -</span>
              <span class="s1">np.asarray(SHORT_RANGE_EXPECTED_FACE_KEY_POINTS))</span>
        <span class="s3">else</span><span class="s1">:</span>
          <span class="s1">prediction_error = np.abs(</span>
              <span class="s1">np.asarray(face_keypoints) -</span>
              <span class="s1">np.asarray(FULL_RANGE_EXPECTED_FACE_KEY_POINTS))</span>

        <span class="s1">self.assertLen(results.detections</span><span class="s3">, </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">self.assertLen(location_data.relative_keypoints</span><span class="s3">, </span><span class="s5">6</span><span class="s1">)</span>
        <span class="s1">npt.assert_array_less(prediction_error</span><span class="s3">, </span><span class="s1">DIFF_THRESHOLD)</span>


<span class="s3">if </span><span class="s1">__name__ == </span><span class="s4">'__main__'</span><span class="s1">:</span>
  <span class="s1">absltest.main()</span>
</pre>
</body>
</html>