<html>
<head>
<title>pose.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
pose.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2020-2021 The MediaPipe Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#      http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>

<span class="s2">&quot;&quot;&quot;MediaPipe Pose.&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">enum</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">NamedTuple</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>

<span class="s0"># The following imports are needed because python pb2 silently discards</span>
<span class="s0"># unknown protobuf fields.</span>
<span class="s0"># pylint: disable=unused-import</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.core </span><span class="s3">import </span><span class="s1">constant_side_packet_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.core </span><span class="s3">import </span><span class="s1">gate_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.core </span><span class="s3">import </span><span class="s1">split_vector_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.image </span><span class="s3">import </span><span class="s1">warp_affine_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.tensor </span><span class="s3">import </span><span class="s1">image_to_tensor_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.tensor </span><span class="s3">import </span><span class="s1">inference_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.tensor </span><span class="s3">import </span><span class="s1">tensors_to_classification_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.tensor </span><span class="s3">import </span><span class="s1">tensors_to_detections_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.tensor </span><span class="s3">import </span><span class="s1">tensors_to_landmarks_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.tensor </span><span class="s3">import </span><span class="s1">tensors_to_segmentation_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.tflite </span><span class="s3">import </span><span class="s1">ssd_anchors_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.util </span><span class="s3">import </span><span class="s1">detections_to_rects_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.util </span><span class="s3">import </span><span class="s1">landmarks_smoothing_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.util </span><span class="s3">import </span><span class="s1">local_file_contents_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.util </span><span class="s3">import </span><span class="s1">logic_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.util </span><span class="s3">import </span><span class="s1">non_max_suppression_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.util </span><span class="s3">import </span><span class="s1">rect_transformation_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.util </span><span class="s3">import </span><span class="s1">thresholding_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.calculators.util </span><span class="s3">import </span><span class="s1">visibility_smoothing_calculator_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.framework.tool </span><span class="s3">import </span><span class="s1">switch_container_pb2</span>
<span class="s0"># pylint: enable=unused-import</span>
<span class="s3">from </span><span class="s1">mediapipe.python.solution_base </span><span class="s3">import </span><span class="s1">SolutionBase</span>
<span class="s3">from </span><span class="s1">mediapipe.python.solutions </span><span class="s3">import </span><span class="s1">download_utils</span>
<span class="s0"># pylint: disable=unused-import</span>
<span class="s3">from </span><span class="s1">mediapipe.python.solutions.pose_connections </span><span class="s3">import </span><span class="s1">POSE_CONNECTIONS</span>
<span class="s0"># pylint: enable=unused-import</span>


<span class="s3">class </span><span class="s1">PoseLandmark(enum.IntEnum):</span>
  <span class="s2">&quot;&quot;&quot;The 33 pose landmarks.&quot;&quot;&quot;</span>
  <span class="s1">NOSE = </span><span class="s4">0</span>
  <span class="s1">LEFT_EYE_INNER = </span><span class="s4">1</span>
  <span class="s1">LEFT_EYE = </span><span class="s4">2</span>
  <span class="s1">LEFT_EYE_OUTER = </span><span class="s4">3</span>
  <span class="s1">RIGHT_EYE_INNER = </span><span class="s4">4</span>
  <span class="s1">RIGHT_EYE = </span><span class="s4">5</span>
  <span class="s1">RIGHT_EYE_OUTER = </span><span class="s4">6</span>
  <span class="s1">LEFT_EAR = </span><span class="s4">7</span>
  <span class="s1">RIGHT_EAR = </span><span class="s4">8</span>
  <span class="s1">MOUTH_LEFT = </span><span class="s4">9</span>
  <span class="s1">MOUTH_RIGHT = </span><span class="s4">10</span>
  <span class="s1">LEFT_SHOULDER = </span><span class="s4">11</span>
  <span class="s1">RIGHT_SHOULDER = </span><span class="s4">12</span>
  <span class="s1">LEFT_ELBOW = </span><span class="s4">13</span>
  <span class="s1">RIGHT_ELBOW = </span><span class="s4">14</span>
  <span class="s1">LEFT_WRIST = </span><span class="s4">15</span>
  <span class="s1">RIGHT_WRIST = </span><span class="s4">16</span>
  <span class="s1">LEFT_PINKY = </span><span class="s4">17</span>
  <span class="s1">RIGHT_PINKY = </span><span class="s4">18</span>
  <span class="s1">LEFT_INDEX = </span><span class="s4">19</span>
  <span class="s1">RIGHT_INDEX = </span><span class="s4">20</span>
  <span class="s1">LEFT_THUMB = </span><span class="s4">21</span>
  <span class="s1">RIGHT_THUMB = </span><span class="s4">22</span>
  <span class="s1">LEFT_HIP = </span><span class="s4">23</span>
  <span class="s1">RIGHT_HIP = </span><span class="s4">24</span>
  <span class="s1">LEFT_KNEE = </span><span class="s4">25</span>
  <span class="s1">RIGHT_KNEE = </span><span class="s4">26</span>
  <span class="s1">LEFT_ANKLE = </span><span class="s4">27</span>
  <span class="s1">RIGHT_ANKLE = </span><span class="s4">28</span>
  <span class="s1">LEFT_HEEL = </span><span class="s4">29</span>
  <span class="s1">RIGHT_HEEL = </span><span class="s4">30</span>
  <span class="s1">LEFT_FOOT_INDEX = </span><span class="s4">31</span>
  <span class="s1">RIGHT_FOOT_INDEX = </span><span class="s4">32</span>


<span class="s1">_BINARYPB_FILE_PATH = </span><span class="s5">'mediapipe/modules/pose_landmark/pose_landmark_cpu.binarypb'</span>


<span class="s3">def </span><span class="s1">_download_oss_pose_landmark_model(model_complexity):</span>
  <span class="s2">&quot;&quot;&quot;Downloads the pose landmark lite/heavy model from the MediaPipe Github repo if it doesn't exist in the package.&quot;&quot;&quot;</span>

  <span class="s3">if </span><span class="s1">model_complexity == </span><span class="s4">0</span><span class="s1">:</span>
    <span class="s1">download_utils.download_oss_model(</span>
        <span class="s5">'mediapipe/modules/pose_landmark/pose_landmark_lite.tflite'</span><span class="s1">)</span>
  <span class="s3">elif </span><span class="s1">model_complexity == </span><span class="s4">2</span><span class="s1">:</span>
    <span class="s1">download_utils.download_oss_model(</span>
        <span class="s5">'mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite'</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">Pose(SolutionBase):</span>
  <span class="s2">&quot;&quot;&quot;MediaPipe Pose. 
 
  MediaPipe Pose processes an RGB image and returns pose landmarks on the most 
  prominent person detected. 
 
  Please refer to https://solutions.mediapipe.dev/pose#python-solution-api for 
  usage examples. 
  &quot;&quot;&quot;</span>

  <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">,</span>
               <span class="s1">static_image_mode=</span><span class="s3">False,</span>
               <span class="s1">model_complexity=</span><span class="s4">1</span><span class="s3">,</span>
               <span class="s1">smooth_landmarks=</span><span class="s3">True,</span>
               <span class="s1">enable_segmentation=</span><span class="s3">False,</span>
               <span class="s1">smooth_segmentation=</span><span class="s3">True,</span>
               <span class="s1">min_detection_confidence=</span><span class="s4">0.5</span><span class="s3">,</span>
               <span class="s1">min_tracking_confidence=</span><span class="s4">0.5</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Initializes a MediaPipe Pose object. 
 
    Args: 
      static_image_mode: Whether to treat the input images as a batch of static 
        and possibly unrelated images, or a video stream. See details in 
        https://solutions.mediapipe.dev/pose#static_image_mode. 
      model_complexity: Complexity of the pose landmark model: 0, 1 or 2. See 
        details in https://solutions.mediapipe.dev/pose#model_complexity. 
      smooth_landmarks: Whether to filter landmarks across different input 
        images to reduce jitter. See details in 
        https://solutions.mediapipe.dev/pose#smooth_landmarks. 
      enable_segmentation: Whether to predict segmentation mask. See details in 
        https://solutions.mediapipe.dev/pose#enable_segmentation. 
      smooth_segmentation: Whether to filter segmentation across different input 
        images to reduce jitter. See details in 
        https://solutions.mediapipe.dev/pose#smooth_segmentation. 
      min_detection_confidence: Minimum confidence value ([0.0, 1.0]) for person 
        detection to be considered successful. See details in 
        https://solutions.mediapipe.dev/pose#min_detection_confidence. 
      min_tracking_confidence: Minimum confidence value ([0.0, 1.0]) for the 
        pose landmarks to be considered tracked successfully. See details in 
        https://solutions.mediapipe.dev/pose#min_tracking_confidence. 
    &quot;&quot;&quot;</span>
    <span class="s1">_download_oss_pose_landmark_model(model_complexity)</span>
    <span class="s1">super().__init__(</span>
        <span class="s1">binary_graph_path=_BINARYPB_FILE_PATH</span><span class="s3">,</span>
        <span class="s1">side_inputs={</span>
            <span class="s5">'model_complexity'</span><span class="s1">: model_complexity</span><span class="s3">,</span>
            <span class="s5">'smooth_landmarks'</span><span class="s1">: smooth_landmarks </span><span class="s3">and not </span><span class="s1">static_image_mode</span><span class="s3">,</span>
            <span class="s5">'enable_segmentation'</span><span class="s1">: enable_segmentation</span><span class="s3">,</span>
            <span class="s5">'smooth_segmentation'</span><span class="s1">:</span>
                <span class="s1">smooth_segmentation </span><span class="s3">and not </span><span class="s1">static_image_mode</span><span class="s3">,</span>
            <span class="s5">'use_prev_landmarks'</span><span class="s1">: </span><span class="s3">not </span><span class="s1">static_image_mode</span><span class="s3">,</span>
        <span class="s1">}</span><span class="s3">,</span>
        <span class="s1">calculator_params={</span>
            <span class="s5">'posedetectioncpu__TensorsToDetectionsCalculator.min_score_thresh'</span><span class="s1">:</span>
                <span class="s1">min_detection_confidence</span><span class="s3">,</span>
            <span class="s5">'poselandmarkbyroicpu__tensorstoposelandmarksandsegmentation__ThresholdingCalculator.threshold'</span><span class="s1">:</span>
                <span class="s1">min_tracking_confidence</span><span class="s3">,</span>
        <span class="s1">}</span><span class="s3">,</span>
        <span class="s1">outputs=[</span><span class="s5">'pose_landmarks'</span><span class="s3">, </span><span class="s5">'pose_world_landmarks'</span><span class="s3">, </span><span class="s5">'segmentation_mask'</span><span class="s1">])</span>

  <span class="s3">def </span><span class="s1">process(self</span><span class="s3">, </span><span class="s1">image: np.ndarray) -&gt; NamedTuple:</span>
    <span class="s2">&quot;&quot;&quot;Processes an RGB image and returns the pose landmarks on the most prominent person detected. 
 
    Args: 
      image: An RGB image represented as a numpy ndarray. 
 
    Raises: 
      RuntimeError: If the underlying graph throws any error. 
      ValueError: If the input image is not three channel RGB. 
 
    Returns: 
      A NamedTuple with fields describing the landmarks on the most prominate 
      person detected: 
        1) &quot;pose_landmarks&quot; field that contains the pose landmarks. 
        2) &quot;pose_world_landmarks&quot; field that contains the pose landmarks in 
        real-world 3D coordinates that are in meters with the origin at the 
        center between hips. 
        3) &quot;segmentation_mask&quot; field that contains the segmentation mask if 
           &quot;enable_segmentation&quot; is set to true. 
    &quot;&quot;&quot;</span>

    <span class="s1">results = super().process(input_data={</span><span class="s5">'image'</span><span class="s1">: image})</span>
    <span class="s3">if </span><span class="s1">results.pose_landmarks:  </span><span class="s0"># pytype: disable=attribute-error</span>
      <span class="s3">for </span><span class="s1">landmark </span><span class="s3">in </span><span class="s1">results.pose_landmarks.landmark:  </span><span class="s0"># pytype: disable=attribute-error</span>
        <span class="s1">landmark.ClearField(</span><span class="s5">'presence'</span><span class="s1">)</span>
    <span class="s3">if </span><span class="s1">results.pose_world_landmarks:  </span><span class="s0"># pytype: disable=attribute-error</span>
      <span class="s3">for </span><span class="s1">landmark </span><span class="s3">in </span><span class="s1">results.pose_world_landmarks.landmark:  </span><span class="s0"># pytype: disable=attribute-error</span>
        <span class="s1">landmark.ClearField(</span><span class="s5">'presence'</span><span class="s1">)</span>
    <span class="s3">return </span><span class="s1">results</span>
</pre>
</body>
</html>