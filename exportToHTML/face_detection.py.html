<html>
<head>
<title>face_detection.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
face_detection.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2021 The MediaPipe Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#      http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>
<span class="s2">&quot;&quot;&quot;MediaPipe Face Detection.&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">enum</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">NamedTuple</span><span class="s3">, </span><span class="s1">Union</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">mediapipe.framework.formats </span><span class="s3">import </span><span class="s1">detection_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.framework.formats </span><span class="s3">import </span><span class="s1">location_data_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.modules.face_detection </span><span class="s3">import </span><span class="s1">face_detection_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.python.solution_base </span><span class="s3">import </span><span class="s1">SolutionBase</span>

<span class="s1">_SHORT_RANGE_GRAPH_FILE_PATH = </span><span class="s4">'mediapipe/modules/face_detection/face_detection_short_range_cpu.binarypb'</span>
<span class="s1">_FULL_RANGE_GRAPH_FILE_PATH = </span><span class="s4">'mediapipe/modules/face_detection/face_detection_full_range_cpu.binarypb'</span>


<span class="s3">def </span><span class="s1">get_key_point(</span>
    <span class="s1">detection: detection_pb2.Detection</span><span class="s3">, </span><span class="s1">key_point_enum: </span><span class="s4">'FaceKeyPoint'</span>
<span class="s1">) -&gt; Union[</span><span class="s3">None, </span><span class="s1">location_data_pb2.LocationData.RelativeKeypoint]:</span>
  <span class="s2">&quot;&quot;&quot;A convenience method to return a face key point by the FaceKeyPoint type. 
 
  Args: 
    detection: A detection proto message that contains face key points. 
    key_point_enum: A FaceKeyPoint type. 
 
  Returns: 
    A RelativeKeypoint proto message. 
  &quot;&quot;&quot;</span>
  <span class="s3">if not </span><span class="s1">detection </span><span class="s3">or not </span><span class="s1">detection.location_data:</span>
    <span class="s3">return None</span>
  <span class="s3">return </span><span class="s1">detection.location_data.relative_keypoints[key_point_enum]</span>


<span class="s3">class </span><span class="s1">FaceKeyPoint(enum.IntEnum):</span>
  <span class="s2">&quot;&quot;&quot;The enum type of the six face detection key points.&quot;&quot;&quot;</span>
  <span class="s1">RIGHT_EYE = </span><span class="s5">0</span>
  <span class="s1">LEFT_EYE = </span><span class="s5">1</span>
  <span class="s1">NOSE_TIP = </span><span class="s5">2</span>
  <span class="s1">MOUTH_CENTER = </span><span class="s5">3</span>
  <span class="s1">RIGHT_EAR_TRAGION = </span><span class="s5">4</span>
  <span class="s1">LEFT_EAR_TRAGION = </span><span class="s5">5</span>


<span class="s3">class </span><span class="s1">FaceDetection(SolutionBase):</span>
  <span class="s2">&quot;&quot;&quot;MediaPipe Face Detection. 
 
  MediaPipe Face Detection processes an RGB image and returns a list of the 
  detected face location data. 
 
  Please refer to 
  https://solutions.mediapipe.dev/face_detection#python-solution-api 
  for usage examples. 
  &quot;&quot;&quot;</span>

  <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">min_detection_confidence=</span><span class="s5">0.5</span><span class="s3">, </span><span class="s1">model_selection=</span><span class="s5">0</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Initializes a MediaPipe Face Detection object. 
 
    Args: 
      min_detection_confidence: Minimum confidence value ([0.0, 1.0]) for face 
        detection to be considered successful. See details in 
        https://solutions.mediapipe.dev/face_detection#min_detection_confidence. 
      model_selection: 0 or 1. 0 to select a short-range model that works 
        best for faces within 2 meters from the camera, and 1 for a full-range 
        model best for faces within 5 meters. See details in 
        https://solutions.mediapipe.dev/face_detection#model_selection. 
    &quot;&quot;&quot;</span>

    <span class="s1">binary_graph_path = _FULL_RANGE_GRAPH_FILE_PATH </span><span class="s3">if </span><span class="s1">model_selection == </span><span class="s5">1 </span><span class="s3">else </span><span class="s1">_SHORT_RANGE_GRAPH_FILE_PATH</span>

    <span class="s1">super().__init__(</span>
        <span class="s1">binary_graph_path=binary_graph_path</span><span class="s3">,</span>
        <span class="s1">graph_options=self.create_graph_options(</span>
            <span class="s1">face_detection_pb2.FaceDetectionOptions()</span><span class="s3">, </span><span class="s1">{</span>
                <span class="s4">'min_score_thresh'</span><span class="s1">: min_detection_confidence</span><span class="s3">,</span>
            <span class="s1">})</span><span class="s3">,</span>
        <span class="s1">outputs=[</span><span class="s4">'detections'</span><span class="s1">])</span>

  <span class="s3">def </span><span class="s1">process(self</span><span class="s3">, </span><span class="s1">image: np.ndarray) -&gt; NamedTuple:</span>
    <span class="s2">&quot;&quot;&quot;Processes an RGB image and returns a list of the detected face location data. 
 
    Args: 
      image: An RGB image represented as a numpy ndarray. 
 
    Raises: 
      RuntimeError: If the underlying graph throws any error. 
      ValueError: If the input image is not three channel RGB. 
 
    Returns: 
      A NamedTuple object with a &quot;detections&quot; field that contains a list of the 
      detected face location data. 
    &quot;&quot;&quot;</span>

    <span class="s3">return </span><span class="s1">super().process(input_data={</span><span class="s4">'image'</span><span class="s1">: image})</span>
</pre>
</body>
</html>