<html>
<head>
<title>image_embedder.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
image_embedder.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2022 The MediaPipe Authors. All Rights Reserved.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>
<span class="s2">&quot;&quot;&quot;MediaPipe image embedder task.&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">dataclasses</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">Callable</span><span class="s3">, </span><span class="s1">Mapping</span><span class="s3">, </span><span class="s1">Optional</span>

<span class="s3">from </span><span class="s1">mediapipe.python </span><span class="s3">import </span><span class="s1">packet_creator</span>
<span class="s3">from </span><span class="s1">mediapipe.python </span><span class="s3">import </span><span class="s1">packet_getter</span>
<span class="s3">from </span><span class="s1">mediapipe.python._framework_bindings </span><span class="s3">import </span><span class="s1">image </span><span class="s3">as </span><span class="s1">image_module</span>
<span class="s3">from </span><span class="s1">mediapipe.python._framework_bindings </span><span class="s3">import </span><span class="s1">packet </span><span class="s3">as </span><span class="s1">packet_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.cc.components.containers.proto </span><span class="s3">import </span><span class="s1">embeddings_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.cc.components.processors.proto </span><span class="s3">import </span><span class="s1">embedder_options_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.cc.vision.image_embedder.proto </span><span class="s3">import </span><span class="s1">image_embedder_graph_options_pb2</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.components.containers </span><span class="s3">import </span><span class="s1">embedding_result </span><span class="s3">as </span><span class="s1">embedding_result_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.components.utils </span><span class="s3">import </span><span class="s1">cosine_similarity</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core </span><span class="s3">import </span><span class="s1">base_options </span><span class="s3">as </span><span class="s1">base_options_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core </span><span class="s3">import </span><span class="s1">task_info </span><span class="s3">as </span><span class="s1">task_info_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.core.optional_dependencies </span><span class="s3">import </span><span class="s1">doc_controls</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.vision.core </span><span class="s3">import </span><span class="s1">base_vision_task_api</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.vision.core </span><span class="s3">import </span><span class="s1">image_processing_options </span><span class="s3">as </span><span class="s1">image_processing_options_module</span>
<span class="s3">from </span><span class="s1">mediapipe.tasks.python.vision.core </span><span class="s3">import </span><span class="s1">vision_task_running_mode </span><span class="s3">as </span><span class="s1">running_mode_module</span>

<span class="s1">ImageEmbedderResult = embedding_result_module.EmbeddingResult</span>
<span class="s1">_BaseOptions = base_options_module.BaseOptions</span>
<span class="s1">_ImageEmbedderGraphOptionsProto = image_embedder_graph_options_pb2.ImageEmbedderGraphOptions</span>
<span class="s1">_EmbedderOptionsProto = embedder_options_pb2.EmbedderOptions</span>
<span class="s1">_RunningMode = running_mode_module.VisionTaskRunningMode</span>
<span class="s1">_TaskInfo = task_info_module.TaskInfo</span>
<span class="s1">_ImageProcessingOptions = image_processing_options_module.ImageProcessingOptions</span>

<span class="s1">_EMBEDDINGS_OUT_STREAM_NAME = </span><span class="s4">'embeddings_out'</span>
<span class="s1">_EMBEDDINGS_TAG = </span><span class="s4">'EMBEDDINGS'</span>
<span class="s1">_IMAGE_IN_STREAM_NAME = </span><span class="s4">'image_in'</span>
<span class="s1">_IMAGE_OUT_STREAM_NAME = </span><span class="s4">'image_out'</span>
<span class="s1">_IMAGE_TAG = </span><span class="s4">'IMAGE'</span>
<span class="s1">_NORM_RECT_STREAM_NAME = </span><span class="s4">'norm_rect_in'</span>
<span class="s1">_NORM_RECT_TAG = </span><span class="s4">'NORM_RECT'</span>
<span class="s1">_TASK_GRAPH_NAME = </span><span class="s4">'mediapipe.tasks.vision.image_embedder.ImageEmbedderGraph'</span>
<span class="s1">_MICRO_SECONDS_PER_MILLISECOND = </span><span class="s5">1000</span>


<span class="s1">@dataclasses.dataclass</span>
<span class="s3">class </span><span class="s1">ImageEmbedderOptions:</span>
  <span class="s2">&quot;&quot;&quot;Options for the image embedder task. 
 
  Attributes: 
    base_options: Base options for the image embedder task. 
    running_mode: The running mode of the task. Default to the image mode. Image 
      embedder task has three running modes: 1) The image mode for embedding 
      image on single image inputs. 2) The video mode for embedding image on the 
      decoded frames of a video. 3) The live stream mode for embedding image on 
      a live stream of input data, such as from camera. 
    l2_normalize: Whether to normalize the returned feature vector with L2 norm. 
      Use this option only if the model does not already contain a native 
      L2_NORMALIZATION TF Lite Op. In most cases, this is already the case and 
      L2 norm is thus achieved through TF Lite inference. 
    quantize: Whether the returned embedding should be quantized to bytes via 
      scalar quantization. Embeddings are implicitly assumed to be unit-norm and 
      therefore any dimension is guaranteed to have a value in [-1.0, 1.0]. Use 
      the l2_normalize option if this is not the case. 
    result_callback: The user-defined result callback for processing live stream 
      data. The result callback should only be specified when the running mode 
      is set to the live stream mode. 
  &quot;&quot;&quot;</span>
  <span class="s1">base_options: _BaseOptions</span>
  <span class="s1">running_mode: _RunningMode = _RunningMode.IMAGE</span>
  <span class="s1">l2_normalize: Optional[bool] = </span><span class="s3">None</span>
  <span class="s1">quantize: Optional[bool] = </span><span class="s3">None</span>
  <span class="s1">result_callback: Optional[Callable[</span>
      <span class="s1">[ImageEmbedderResult</span><span class="s3">, </span><span class="s1">image_module.Image</span><span class="s3">, </span><span class="s1">int]</span><span class="s3">, None</span><span class="s1">]] = </span><span class="s3">None</span>

  <span class="s1">@doc_controls.do_not_generate_docs</span>
  <span class="s3">def </span><span class="s1">to_pb2(self) -&gt; _ImageEmbedderGraphOptionsProto:</span>
    <span class="s2">&quot;&quot;&quot;Generates an ImageEmbedderOptions protobuf object.&quot;&quot;&quot;</span>
    <span class="s1">base_options_proto = self.base_options.to_pb2()</span>
    <span class="s1">base_options_proto.use_stream_mode = </span><span class="s3">False if </span><span class="s1">self.running_mode == _RunningMode.IMAGE </span><span class="s3">else True</span>
    <span class="s1">embedder_options_proto = _EmbedderOptionsProto(</span>
        <span class="s1">l2_normalize=self.l2_normalize</span><span class="s3">, </span><span class="s1">quantize=self.quantize)</span>

    <span class="s3">return </span><span class="s1">_ImageEmbedderGraphOptionsProto(</span>
        <span class="s1">base_options=base_options_proto</span><span class="s3">,</span>
        <span class="s1">embedder_options=embedder_options_proto)</span>


<span class="s3">class </span><span class="s1">ImageEmbedder(base_vision_task_api.BaseVisionTaskApi):</span>
  <span class="s2">&quot;&quot;&quot;Class that performs embedding extraction on images. 
 
  The API expects a TFLite model with optional, but strongly recommended, 
  TFLite Model Metadata. 
 
  Input tensor: 
    (kTfLiteUInt8/kTfLiteFloat32) 
    - image input of size `[batch x height x width x channels]`. 
    - batch inference is not supported (`batch` is required to be 1). 
    - only RGB inputs are supported (`channels` is required to be 3). 
    - if type is kTfLiteFloat32, NormalizationOptions are required to be 
      attached to the metadata for input normalization. 
  At least one output tensor with: 
    (kTfLiteUInt8/kTfLiteFloat32) 
    - `N` components corresponding to the `N` dimensions of the returned 
      feature vector for this output layer. 
    - Either 2 or 4 dimensions, i.e. `[1 x N]` or `[1 x 1 x 1 x N]`. 
  &quot;&quot;&quot;</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">create_from_model_path(cls</span><span class="s3">, </span><span class="s1">model_path: str) -&gt; </span><span class="s4">'ImageEmbedder'</span><span class="s1">:</span>
    <span class="s2">&quot;&quot;&quot;Creates an `ImageEmbedder` object from a TensorFlow Lite model and the default `ImageEmbedderOptions`. 
 
    Note that the created `ImageEmbedder` instance is in image mode, for 
    embedding image on single image inputs. 
 
    Args: 
      model_path: Path to the model. 
 
    Returns: 
      `ImageEmbedder` object that's created from the model file and the default 
      `ImageEmbedderOptions`. 
 
    Raises: 
      ValueError: If failed to create `ImageEmbedder` object from the provided 
        file such as invalid file path. 
      RuntimeError: If other types of error occurred. 
    &quot;&quot;&quot;</span>
    <span class="s1">base_options = _BaseOptions(model_asset_path=model_path)</span>
    <span class="s1">options = ImageEmbedderOptions(</span>
        <span class="s1">base_options=base_options</span><span class="s3">, </span><span class="s1">running_mode=_RunningMode.IMAGE)</span>
    <span class="s3">return </span><span class="s1">cls.create_from_options(options)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">create_from_options(cls</span><span class="s3">,</span>
                          <span class="s1">options: ImageEmbedderOptions) -&gt; </span><span class="s4">'ImageEmbedder'</span><span class="s1">:</span>
    <span class="s2">&quot;&quot;&quot;Creates the `ImageEmbedder` object from image embedder options. 
 
    Args: 
      options: Options for the image embedder task. 
 
    Returns: 
      `ImageEmbedder` object that's created from `options`. 
 
    Raises: 
      ValueError: If failed to create `ImageEmbedder` object from 
        `ImageEmbedderOptions` such as missing the model. 
      RuntimeError: If other types of error occurred. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">packets_callback(output_packets: Mapping[str</span><span class="s3">, </span><span class="s1">packet_module.Packet]):</span>
      <span class="s3">if </span><span class="s1">output_packets[_IMAGE_OUT_STREAM_NAME].is_empty():</span>
        <span class="s3">return</span>

      <span class="s1">embedding_result_proto = embeddings_pb2.EmbeddingResult()</span>
      <span class="s1">embedding_result_proto.CopyFrom(</span>
          <span class="s1">packet_getter.get_proto(output_packets[_EMBEDDINGS_OUT_STREAM_NAME]))</span>

      <span class="s1">image = packet_getter.get_image(output_packets[_IMAGE_OUT_STREAM_NAME])</span>
      <span class="s1">timestamp = output_packets[_IMAGE_OUT_STREAM_NAME].timestamp</span>
      <span class="s1">options.result_callback(</span>
          <span class="s1">ImageEmbedderResult.create_from_pb2(embedding_result_proto)</span><span class="s3">, </span><span class="s1">image</span><span class="s3">,</span>
          <span class="s1">timestamp.value // _MICRO_SECONDS_PER_MILLISECOND)</span>

    <span class="s1">task_info = _TaskInfo(</span>
        <span class="s1">task_graph=_TASK_GRAPH_NAME</span><span class="s3">,</span>
        <span class="s1">input_streams=[</span>
            <span class="s4">':'</span><span class="s1">.join([_IMAGE_TAG</span><span class="s3">, </span><span class="s1">_IMAGE_IN_STREAM_NAME])</span><span class="s3">,</span>
            <span class="s4">':'</span><span class="s1">.join([_NORM_RECT_TAG</span><span class="s3">, </span><span class="s1">_NORM_RECT_STREAM_NAME])</span><span class="s3">,</span>
        <span class="s1">]</span><span class="s3">,</span>
        <span class="s1">output_streams=[</span>
            <span class="s4">':'</span><span class="s1">.join([_EMBEDDINGS_TAG</span><span class="s3">, </span><span class="s1">_EMBEDDINGS_OUT_STREAM_NAME])</span><span class="s3">,</span>
            <span class="s4">':'</span><span class="s1">.join([_IMAGE_TAG</span><span class="s3">, </span><span class="s1">_IMAGE_OUT_STREAM_NAME])</span>
        <span class="s1">]</span><span class="s3">,</span>
        <span class="s1">task_options=options)</span>
    <span class="s3">return </span><span class="s1">cls(</span>
        <span class="s1">task_info.generate_graph_config(</span>
            <span class="s1">enable_flow_limiting=options.running_mode ==</span>
            <span class="s1">_RunningMode.LIVE_STREAM)</span><span class="s3">, </span><span class="s1">options.running_mode</span><span class="s3">,</span>
        <span class="s1">packets_callback </span><span class="s3">if </span><span class="s1">options.result_callback </span><span class="s3">else None</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">embed(</span>
      <span class="s1">self</span><span class="s3">,</span>
      <span class="s1">image: image_module.Image</span><span class="s3">,</span>
      <span class="s1">image_processing_options: Optional[_ImageProcessingOptions] = </span><span class="s3">None</span>
  <span class="s1">) -&gt; ImageEmbedderResult:</span>
    <span class="s2">&quot;&quot;&quot;Performs image embedding extraction on the provided MediaPipe Image. 
 
     Extraction is performed on the region of interest specified by the `roi` 
     argument if provided, or on the entire image otherwise. 
 
    Args: 
      image: MediaPipe Image. 
      image_processing_options: Options for image processing. 
 
    Returns: 
      An embedding result object that contains a list of embeddings. 
 
    Raises: 
      ValueError: If any of the input arguments is invalid. 
      RuntimeError: If image embedder failed to run. 
    &quot;&quot;&quot;</span>
    <span class="s1">normalized_rect = self.convert_to_normalized_rect(image_processing_options)</span>
    <span class="s1">output_packets = self._process_image_data({</span>
        <span class="s1">_IMAGE_IN_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_image(image)</span><span class="s3">,</span>
        <span class="s1">_NORM_RECT_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_proto(normalized_rect.to_pb2())</span>
    <span class="s1">})</span>

    <span class="s1">embedding_result_proto = embeddings_pb2.EmbeddingResult()</span>
    <span class="s1">embedding_result_proto.CopyFrom(</span>
        <span class="s1">packet_getter.get_proto(output_packets[_EMBEDDINGS_OUT_STREAM_NAME]))</span>

    <span class="s3">return </span><span class="s1">ImageEmbedderResult.create_from_pb2(embedding_result_proto)</span>

  <span class="s3">def </span><span class="s1">embed_for_video(</span>
      <span class="s1">self</span><span class="s3">,</span>
      <span class="s1">image: image_module.Image</span><span class="s3">,</span>
      <span class="s1">timestamp_ms: int</span><span class="s3">,</span>
      <span class="s1">image_processing_options: Optional[_ImageProcessingOptions] = </span><span class="s3">None</span>
  <span class="s1">) -&gt; ImageEmbedderResult:</span>
    <span class="s2">&quot;&quot;&quot;Performs image embedding extraction on the provided video frames. 
 
    Extraction is performed on the region of interested specified by the `roi` 
    argument if provided, or on the entire image otherwise. 
 
    Only use this method when the ImageEmbedder is created with the video 
    running mode. It's required to provide the video frame's timestamp (in 
    milliseconds) along with the video frame. The input timestamps should be 
    monotonically increasing for adjacent calls of this method. 
 
    Args: 
      image: MediaPipe Image. 
      timestamp_ms: The timestamp of the input video frame in milliseconds. 
      image_processing_options: Options for image processing. 
 
    Returns: 
      An embedding result object that contains a list of embeddings. 
 
    Raises: 
      ValueError: If any of the input arguments is invalid. 
      RuntimeError: If image embedder failed to run. 
    &quot;&quot;&quot;</span>
    <span class="s1">normalized_rect = self.convert_to_normalized_rect(image_processing_options)</span>
    <span class="s1">output_packets = self._process_video_data({</span>
        <span class="s1">_IMAGE_IN_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_image(image).at(</span>
                <span class="s1">timestamp_ms * _MICRO_SECONDS_PER_MILLISECOND)</span><span class="s3">,</span>
        <span class="s1">_NORM_RECT_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_proto(normalized_rect.to_pb2()).at(</span>
                <span class="s1">timestamp_ms * _MICRO_SECONDS_PER_MILLISECOND)</span>
    <span class="s1">})</span>
    <span class="s1">embedding_result_proto = embeddings_pb2.EmbeddingResult()</span>
    <span class="s1">embedding_result_proto.CopyFrom(</span>
        <span class="s1">packet_getter.get_proto(output_packets[_EMBEDDINGS_OUT_STREAM_NAME]))</span>

    <span class="s3">return </span><span class="s1">ImageEmbedderResult.create_from_pb2(embedding_result_proto)</span>

  <span class="s3">def </span><span class="s1">embed_async(</span>
      <span class="s1">self</span><span class="s3">,</span>
      <span class="s1">image: image_module.Image</span><span class="s3">,</span>
      <span class="s1">timestamp_ms: int</span><span class="s3">,</span>
      <span class="s1">image_processing_options: Optional[_ImageProcessingOptions] = </span><span class="s3">None</span>
  <span class="s1">) -&gt; </span><span class="s3">None</span><span class="s1">:</span>
    <span class="s2">&quot;&quot;&quot;Sends live image data to embedder. 
 
    The results will be available via the &quot;result_callback&quot; provided in the 
    ImageEmbedderOptions. Embedding extraction is performed on the region of 
    interested specified by the `roi` argument if provided, or on the entire 
    image otherwise. 
 
    Only use this method when the ImageEmbedder is created with the live 
    stream running mode. The input timestamps should be monotonically increasing 
    for adjacent calls of this method. This method will return immediately after 
    the input image is accepted. The results will be available via the 
    `result_callback` provided in the `ImageEmbedderOptions`. The 
    `embed_async` method is designed to process live stream data such as 
    camera input. To lower the overall latency, image embedder may drop the 
    input images if needed. In other words, it's not guaranteed to have output 
    per input image. 
 
    The `result_callback` provides: 
      - An embedding result object that contains a list of embeddings. 
      - The input image that the image embedder runs on. 
      - The input timestamp in milliseconds. 
 
    Args: 
      image: MediaPipe Image. 
      timestamp_ms: The timestamp of the input image in milliseconds. 
      image_processing_options: Options for image processing. 
 
    Raises: 
      ValueError: If the current input timestamp is smaller than what the image 
        embedder has already processed. 
    &quot;&quot;&quot;</span>
    <span class="s1">normalized_rect = self.convert_to_normalized_rect(image_processing_options)</span>
    <span class="s1">self._send_live_stream_data({</span>
        <span class="s1">_IMAGE_IN_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_image(image).at(</span>
                <span class="s1">timestamp_ms * _MICRO_SECONDS_PER_MILLISECOND)</span><span class="s3">,</span>
        <span class="s1">_NORM_RECT_STREAM_NAME:</span>
            <span class="s1">packet_creator.create_proto(normalized_rect.to_pb2()).at(</span>
                <span class="s1">timestamp_ms * _MICRO_SECONDS_PER_MILLISECOND)</span>
    <span class="s1">})</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">cosine_similarity(cls</span><span class="s3">, </span><span class="s1">u: embedding_result_module.Embedding</span><span class="s3">,</span>
                        <span class="s1">v: embedding_result_module.Embedding) -&gt; float:</span>
    <span class="s2">&quot;&quot;&quot;Utility function to compute cosine similarity between two embedding entries. 
 
    May return an InvalidArgumentError if e.g. the feature vectors are of 
    different types (quantized vs. float), have different sizes, or have an 
    L2-norm of 0. 
 
    Args: 
      u: An embedding entry. 
      v: An embedding entry. 
 
    Returns: 
      The cosine similarity for the two embeddings. 
 
    Raises: 
      ValueError: May return an error if e.g. the feature vectors are of 
        different types (quantized vs. float), have different sizes, or have 
        an L2-norm of 0. 
    &quot;&quot;&quot;</span>
    <span class="s3">return </span><span class="s1">cosine_similarity.cosine_similarity(u</span><span class="s3">, </span><span class="s1">v)</span>
</pre>
</body>
</html>